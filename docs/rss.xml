<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>V's Blog</title><link>https://blog.witter.top</link><description>自有清风常载鹤，从无猜意不惊鸥。</description><copyright>V's Blog</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://img.witter.top/file/b037878209903b7d5bb17.jpg</url><title>avatar</title><link>https://blog.witter.top</link></image><lastBuildDate>Sun, 23 Jun 2024 15:04:24 +0000</lastBuildDate><managingEditor>V's Blog</managingEditor><ttl>60</ttl><webMaster>V's Blog</webMaster><item><title>0-1 部署监控告警系统(Prometheus)</title><link>https://blog.witter.top/post/0-1%20-bu-shu-jian-kong-gao-jing-xi-tong-%28Prometheus%29.html</link><description>**完整docker-compose.yml**&#13;
&#13;
```yaml&#13;
networks:&#13;
  monitor:&#13;
    name: monitor&#13;
    driver: bridge&#13;
&#13;
services:&#13;
  prometheus:&#13;
    image: prom/prometheus:latest&#13;
    ports:&#13;
      - 9090:9090&#13;
    restart: always&#13;
    volumes:&#13;
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml&#13;
      - ./prometheus/:/etc/prometheus&#13;
    networks:&#13;
      - monitor&#13;
    container_name: prometheus&#13;
    environment:&#13;
      - --web.enable-admin-api&#13;
      - --web.enable-lifecycle&#13;
&#13;
  node-exporter:&#13;
    image: quay.io/prometheus/node-exporter:latest&#13;
    container_name: node-exporter&#13;
    restart: always&#13;
    network_mode: host&#13;
    pid: host&#13;
    volumes:&#13;
      - /:/host:ro,rslave&#13;
    command: --path.rootfs=/host&#13;
    depends_on:&#13;
      - prometheus&#13;
&#13;
  blackbox-exporter:&#13;
    image: quay.io/prometheus/blackbox-exporter:latest&#13;
    container_name: blackbox-exporter&#13;
    restart: always&#13;
    ports:&#13;
      - '9115:9115'&#13;
    volumes:&#13;
      - ./blackbox-exporter/:/config&#13;
    command: --config.file=/config/blackbox.yml&#13;
    depends_on:&#13;
      - prometheus&#13;
&#13;
  alertmanager:&#13;
      image: prom/alertmanager:latest&#13;
      container_name: alertmanager&#13;
      restart: always&#13;
      volumes:&#13;
          - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml&#13;
      ports:&#13;
          - '9093:9093'&#13;
      networks:&#13;
          - monitor&#13;
&#13;
  dingtalk-webhook:&#13;
    image: timonwong/prometheus-webhook-dingtalk:latest&#13;
    restart: always&#13;
    volumes:&#13;
      - ./dingtalk-webhook/config.yml:/etc/prometheus-webhook-dingtalk/config.yml&#13;
      - ./dingtalk-webhook/prometheus-webhook-dingtalk:/prometheus-webhook-dingtalk&#13;
      - ./dingtalk-webhook/templates:/etc/prometheus-webhook-dingtalk/templates&#13;
    ports:&#13;
      - 8060:8060&#13;
    command: '--web.enable-ui'&#13;
    networks:&#13;
      - monitor&#13;
    container_name: dingtalk-webhook&#13;
    depends_on:&#13;
      - prometheus&#13;
      - node-exporter&#13;
      - blackbox-exporter&#13;
&#13;
  grafana:&#13;
    image: grafana/grafana-enterprise&#13;
    user: root&#13;
    restart: always&#13;
    ports:&#13;
      - 3000:3000&#13;
    networks:&#13;
      - monitor&#13;
    volumes:&#13;
      - ./grafana/data:/var/lib/grafana&#13;
    container_name: grafana&#13;
    depends_on:&#13;
      - prometheus&#13;
```&#13;
&#13;
## 1.Prometheus&#13;
&#13;
&gt; Prometheus只说明进行自我修改的部分，基本的安装步骤不再赘述！&#13;
&#13;
### 1.1 部署方式&#13;
&#13;
**本机部署**&#13;
&#13;
二进制文件[[下载链接](https://prometheus.io/download/)](https://prometheus.io/download/)&#13;
&#13;
```shell&#13;
# prometheus-2.53.0.linux-amd64.tar.gz 对下载后的二进制文件进行解压&#13;
&#13;
# 首次启动命令&#13;
nohup ./prometheus --config.file=prometheus.yml --storage.tsdb.retention.time=90d --web.enable-lifecycle &amp;&#13;
&#13;
# check.sh -&gt; 二进制文件部署方式的热重载脚本&#13;
#========================================&#13;
#!/bin/bash&#13;
# 定义Prometheus配置文件路径&#13;
prometheus_config='./prometheus/prometheus.yml'&#13;
# 检查配置文件&#13;
check_result=$(./promtool check config '$prometheus_config' 2&gt;&amp;1)&#13;
if [[ $check_result =~ 'FAILED' ]]; then&#13;
  # 配置文件检查失败，输出错误信息&#13;
  echo 'Prometheus config check failed!'&#13;
  echo '$check_result'&#13;
  exit 1&#13;
else&#13;
  # 配置文件检查成功，执行重载&#13;
  curl -X POST http://localhost:9090/-/reload&#13;
  echo 'Prometheus config check successful!'&#13;
fi&#13;
#========================================&#13;
```&#13;
&#13;
**systemd部署**&#13;
&#13;
```shell&#13;
# 可选添加用户&#13;
sudo useradd --no-create-home --shell /bin/false prometheus&#13;
# prometheus.service 文件&#13;
&#13;
[Unit]&#13;
Description=Prometheus&#13;
Wants=network-online.target&#13;
After=network-online.target&#13;
&#13;
[Service]&#13;
User=prometheus&#13;
Group=prometheus&#13;
Type=simple&#13;
ExecStart=/usr/local/bin/prometheus \&#13;
  --config.file=/etc/prometheus/prometheus.yml \&#13;
  --storage.tsdb.path=/var/lib/prometheus/ \&#13;
  --web.console.templates=/usr/share/prometheus/consoles \&#13;
  --web.console.libraries=/usr/share/prometheus/console_libraries&#13;
&#13;
[Install]&#13;
WantedBy=multi-user.target&#13;
&#13;
# 进行对应的初次重载命令&#13;
sudo systemctl daemon-reload&#13;
sudo systemctl enable prometheus&#13;
sudo systemctl start prometheus&#13;
sudo systemctl status prometheus&#13;
```&#13;
&#13;
**docker-compose部署**&#13;
&#13;
```yaml&#13;
networks:&#13;
  monitor:&#13;
    name: monitor&#13;
    driver: bridge&#13;
&#13;
services:&#13;
  prometheus:&#13;
    image: prom/prometheus:latest&#13;
    ports:&#13;
      - 9090:9090&#13;
    restart: always&#13;
    volumes:&#13;
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml&#13;
      - ./prometheus/:/etc/prometheus&#13;
    networks:&#13;
      - monitor&#13;
    container_name: prometheus&#13;
    environment:&#13;
      - --web.enable-admin-api&#13;
      - --web.enable-lifecycle&#13;
```&#13;
&#13;
### 1.2 主配置文件&#13;
&#13;
&gt; 采用Git+Jenkins(CI/CD)+Docker方式，通过本地编辑 -&gt; 推送Git -&gt; CI/CD执行拉取和热更新 -&gt; 完成配置文件修改步骤&#13;
&#13;
`prometheus.yml`&#13;
&#13;
```yaml&#13;
# my global config&#13;
global:&#13;
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.&#13;
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.&#13;
  # scrape_timeout is set to the global default (10s).&#13;
&#13;
# Alertmanager configuration&#13;
alerting:&#13;
  alertmanagers:&#13;
    - static_configs:&#13;
        - targets:&#13;
           - alertmanager:9093&#13;
&#13;
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.&#13;
# 可以为通配符路径，注意是宿主机路径还是容器路径&#13;
rule_files:&#13;
  # - 'first_rules.yml'&#13;
  # - 'second_rules.yml'&#13;
  - ./rules/*.yml&#13;
&#13;
# A scrape configuration containing exactly one endpoint to scrape:&#13;
# Here it's Prometheus itself.&#13;
scrape_configs:&#13;
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.&#13;
  - job_name: 'prometheus'&#13;
    # metrics_path defaults to '/metrics'&#13;
    # scheme defaults to 'http'.&#13;
    static_configs:&#13;
      - targets: ['localhost:9090']&#13;
&#13;
  - job_name: 'node_exporter'&#13;
    metrics_path: /metrics&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./node-exporter/*.yml']&#13;
        refresh_interval: 15s&#13;
    relabel_configs:&#13;
      - source_labels: [__address__]&#13;
        regex: (.*)&#13;
        target_label: __address__&#13;
        replacement: $1&#13;
&#13;
  - job_name: 'blackbox_http_2xx'&#13;
    scrape_interval: 90s&#13;
    metrics_path: /probe&#13;
    params:&#13;
      module:&#13;
      - http_2xx&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./blackbox_http_2xx/*.yml']&#13;
        refresh_interval: 15s&#13;
    relabel_configs:&#13;
      - source_labels: [__address__]&#13;
        target_label: __param_target&#13;
      - source_labels: [__param_target]&#13;
        target_label: instance&#13;
      - target_label: __address__&#13;
        replacement: localhost:9115  # blackbox_exporter所在的机器和端口&#13;
&#13;
  - job_name: 'blackbox_http_3min'&#13;
    scrape_interval: 3m # 可以单独调整blackbox的抓取频率&#13;
    metrics_path: /probe&#13;
    params:&#13;
      module:&#13;
      - http_2xx&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./blackbox_http_3min/*.yml']&#13;
        refresh_interval: 15s&#13;
    relabel_configs:&#13;
      - source_labels: [__address__]&#13;
        target_label: __param_target&#13;
      - source_labels: [__param_target]&#13;
        target_label: instance&#13;
      - target_label: __address__&#13;
        replacement: localhost:9115  # blackbox_exporter所在的机器和端口&#13;
&#13;
  - job_name: 'blackbox_tcp_connect'&#13;
    metrics_path: /probe&#13;
    params:&#13;
      module:&#13;
      - tcp_connect&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./blackbox_tcp_connect/*.yml']&#13;
        refresh_interval: 15s&#13;
    relabel_configs:&#13;
      - source_labels: [__address__]&#13;
        target_label: __param_target&#13;
      - source_labels: [__param_target]&#13;
        target_label: instance&#13;
      - target_label: __address__&#13;
        replacement: localhost:9115  # blackbox_exporter所在的机器和端口&#13;
&#13;
  - job_name: 'blackbox_ping'&#13;
    metrics_path: /probe&#13;
    params:&#13;
      module:&#13;
      - icmp&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./blackbox_ping/*.yml']&#13;
        refresh_interval: 15s&#13;
    relabel_configs:&#13;
      - source_labels: [__address__]&#13;
        target_label: __param_target&#13;
      - source_labels: [__param_target]&#13;
        target_label: instance&#13;
      - target_label: __address__&#13;
        replacement: localhost:9115  # blackbox_exporter所在的机器和端口&#13;
&#13;
# 以下为大数据Hadoop所需的exporter&#13;
  - job_name: 'fsimage'&#13;
    scrape_interval: 1m   # Depends on how often the name node writes a fsimage file.&#13;
    scrape_timeout: 40s    # Depends on size&#13;
    static_configs:&#13;
      - targets: [ 'xxxx:9709' ]&#13;
        labels:&#13;
          project: fsimage&#13;
&#13;
  - job_name: 'kafka-exporter'&#13;
    scrape_interval: 20s&#13;
    scrape_timeout: 15s&#13;
    static_configs:&#13;
      - targets: ['xxxx:9308']&#13;
        labels:&#13;
          project: kafka-exporter&#13;
          instance: xxxx:9308&#13;
&#13;
  - job_name: 'jmx-exporter'&#13;
    metrics_path: /metrics&#13;
    static_configs:&#13;
    file_sd_configs:&#13;
      - files: ['./jmx-exporter/*.yml']&#13;
        refresh_interval: 15s&#13;
```&#13;
&#13;
### 1.3 从配置文件&#13;
&#13;
`node-exporter.yml`&#13;
&#13;
```yaml&#13;
- targets:&#13;
  - xxxx:9100&#13;
  labels:    &#13;
    project: configure by ur self&#13;
    instance: xxx:9100&#13;
    name: configure by ur self&#13;
```&#13;
&#13;
`blackbox-exporter.yml`&#13;
&#13;
```yaml&#13;
- targets:&#13;
  - put a url on this line, include https or http&#13;
  labels:&#13;
    project: configure by ur self&#13;
    service: xxx&#13;
```&#13;
&#13;
`jmx-exporter.yml`&#13;
&#13;
```yaml&#13;
- targets:&#13;
    - kafka:9803&#13;
  labels:&#13;
    project: node-exporter&#13;
    instance: kafka:9803&#13;
    process: kafka&#13;
```&#13;
&#13;
`node-rules.yml`&#13;
&#13;
```yaml&#13;
groups:&#13;
  - name: 服务器状态监控&#13;
    rules:&#13;
      - alert: CPU 监控&#13;
        expr: round((1 - avg(rate(node_cpu_seconds_total{instance='xxxxx:9100',mode='idle'}[1m])) by (instance)) * 100, 0.01) &gt; 80&#13;
        for: 1m&#13;
        labels:&#13;
          severity: critical&#13;
        annotations:&#13;
          summary: 服务器CPU占用率高&#13;
          description: '{{$labels.instance}}服务器 CPU 已使用: {{$value}}%'&#13;
      - alert: 内存监控&#13;
        expr: round((1 - (node_memory_MemAvailable_bytes{instance='xxxxx:9100'} / (node_memory_MemTotal_bytes{instance='xxxxx:9100'})))* 100,0.01) &gt; 95&#13;
        for: 1m&#13;
        labels:&#13;
          severity: critical&#13;
        annotations:&#13;
          summary: 服务器内存占用过高&#13;
          description: '{{$labels.instance}}服务器内存已使用: {{$value}}%'&#13;
      - alert: 磁盘监控&#13;
        expr: round((node_filesystem_size_bytes{instance='xxxxx:9100',mountpoint='/'}-node_filesystem_free_bytes{instance='xxxxx:9100',mountpoint='/'})*100/(node_filesystem_avail_bytes{instance='xxxxx:9100',mountpoint='/'}+(node_filesystem_size_bytes{instance='xxxxx:9100',mountpoint='/'}-node_filesystem_free_bytes{instance='xxxxx:9100',mountpoint='/'})),0.01) &gt; 90&#13;
        for: 1m&#13;
        labels:&#13;
          severity: critical&#13;
        annotations:&#13;
          summary: 服务器磁盘占用过高&#13;
          description: '{{$labels.instance}}服务器磁盘已使用: {{$value}}%'&#13;
      - alert: 网络连接数监控&#13;
        expr: node_netstat_Tcp_CurrEstab{instance='xxxxx:9100'} &gt; 500&#13;
        for: 1m&#13;
        labels:&#13;
          severity: critical&#13;
        annotations:&#13;
          summary: 服务器网络连接数过高&#13;
          description: '{{$labels.instance}}服务器当前网络连接数: {{$value}}'&#13;
```&#13;
&#13;
`blackbox-rules.yml`&#13;
&#13;
```yaml&#13;
groups:&#13;
- name: hosts监控&#13;
  rules:&#13;
  - alert: 状态码监控(monitor)&#13;
    expr: probe_http_status_code{service='xxx'} != 200&#13;
    for: 1m&#13;
    labels:&#13;
      severity: critical&#13;
    annotations:&#13;
      summary: xxx状态码不为200(monitor)&#13;
      description: '检测服务: {{$labels.service}}, 状态码为: {{$value}}'&#13;
```&#13;
&#13;
## 2.Grafana&#13;
&#13;
&gt; Grafana不在赘述配置dashboard等基础环节，只写一些流传较为少的配置方法&#13;
&#13;
### 2.1 部署方式&#13;
&#13;
**docker-compose部署**&#13;
&#13;
*在执行docker compose up -d之前，需要先执行docker run的步骤将想要持久化的容器内文件通过docker cp拷贝到宿主机上！*&#13;
&#13;
```yaml&#13;
  grafana:&#13;
    image: grafana/grafana-enterprise&#13;
    user: root&#13;
    restart: always&#13;
    ports:&#13;
      - 3000:3000&#13;
    networks:&#13;
      - monitor&#13;
    volumes:&#13;
      - ./grafana/data:/var/lib/grafana&#13;
      - ./grafana/plugins:/var/lib/grafana/plugins&#13;
      - ./grafana/log:/var/log/grafana&#13;
      - ./grafana/conf:/etc/grafana&#13;
    container_name: grafana&#13;
    depends_on:&#13;
      - prometheus&#13;
    extra_hosts:&#13;
      - 'url:ip_address'&#13;
```&#13;
&#13;
### 2.2 连接LDAP&#13;
&#13;
**设置配置文件中的auth.ldap为true  文件路径：`/usr/share/grafana/conf/defaults.ini`**&#13;
&#13;
```ini&#13;
[auth.ldap]&#13;
# Set to `true` to enable LDAP integration (default: `false`)&#13;
enabled = true&#13;
&#13;
# Path to the LDAP specific configuration file (default: `/etc/grafana/ldap.toml`)&#13;
config_file = /etc/grafana/ldap.toml&#13;
&#13;
# Allow sign-up should be `true` (default) to allow Grafana to create users on successful LDAP authentication.&#13;
# If set to `false` only already existing Grafana users will be able to login.&#13;
allow_sign_up = true&#13;
```&#13;
&#13;
**添加ldap相关的设置   文件路径：`/etc/grafana/ldap.toml`**&#13;
&#13;
```toml&#13;
# To troubleshoot and get more log info enable ldap debug logging in grafana.ini&#13;
# [log]&#13;
# filters = ldap:debug&#13;
[[servers]]&#13;
# Ldap server host (specify multiple hosts space separated)&#13;
host = 'xxxxx'&#13;
# Default port is 389 or 636 if use_ssl = true&#13;
port = 636&#13;
# Set to true if LDAP server should use an encrypted TLS connection (either with STARTTLS or LDAPS)&#13;
use_ssl = true&#13;
# If set to true, use LDAP with STARTTLS instead of LDAPS&#13;
start_tls = false&#13;
# set to true if you want to skip ssl cert validation&#13;
ssl_skip_verify = false&#13;
# set to the path to your root CA certificate or leave unset to use system defaults&#13;
# root_ca_cert = '/path/to/certificate.crt'&#13;
# Authentication against LDAP servers requiring client certificates&#13;
# client_cert = '/path/to/client.crt'&#13;
# client_key = '/path/to/client.key'&#13;
&#13;
# Search user bind dn&#13;
bind_dn = 'uid=xxxxx,cn=users,cn=accounts,dc=xxxxxxx,dc=cn'&#13;
# Search user bind password&#13;
# If the password contains # or ; you have to wrap it with triple quotes. Ex '''#password;'''&#13;
bind_password = ''''''&#13;
&#13;
# Timeout in seconds (applies to each host specified in the 'host' entry (space separated))&#13;
timeout = 10&#13;
&#13;
# User search filter, for example '(cn=%s)' or '(sAMAccountName=%s)' or '(uid=%s)'&#13;
search_filter = '(uid=%s)'&#13;
&#13;
# An array of base dns to search through&#13;
search_base_dns = ['cn=users,cn=accounts,dc=xxx,dc=cn']&#13;
&#13;
## For Posix or LDAP setups that does not support member_of attribute you can define the below settings&#13;
## Please check grafana LDAP docs for examples&#13;
#group_search_filter = '(&amp;(objectClass=groupOfNames)(memberOf=%s))'&#13;
#group_search_base_dns = ['cn=groups,cn=accounts,dc=xxx,dc=cn']&#13;
#group_search_filter_user_attribute = 'uid'&#13;
&#13;
# Specify names of the ldap attributes your ldap uses&#13;
[servers.attributes]&#13;
name = 'givenName'&#13;
surname = 'uid'&#13;
username = 'uid'&#13;
member_of = 'memberOf'&#13;
email =  'mail'&#13;
&#13;
# Map ldap groups to grafana org roles&#13;
[[servers.group_mappings]]&#13;
group_dn = 'cn=admins,cn=groups,cn=accounts,dc=xxxxx,dc=cn'&#13;
org_role = 'Admin'&#13;
# To make user an instance admin  (Grafana Admin) uncomment line below&#13;
grafana_admin = true&#13;
# The Grafana organization database id, optional, if left out the default org (id 1) will be used&#13;
# org_id = 1&#13;
&#13;
[[servers.group_mappings]]&#13;
group_dn = 'cn=users,cn=groups,cn=accounts,dc=xxxxx,dc=cn'&#13;
org_role = 'Editor'&#13;
&#13;
#[[servers.group_mappings]]&#13;
# If you want to match all (or no ldap groups) then you can use wildcard&#13;
#group_dn = '*'&#13;
#org_role = 'Viewer'&#13;
```。</description><guid isPermaLink="true">https://blog.witter.top/post/0-1%20-bu-shu-jian-kong-gao-jing-xi-tong-%28Prometheus%29.html</guid><pubDate>Sun, 23 Jun 2024 14:32:24 +0000</pubDate></item><item><title>Jenkins-Kubernetes相结合</title><link>https://blog.witter.top/post/Jenkins-Kubernetes-xiang-jie-he.html</link><description>&#13;
## 1.安装/部署&#13;
&#13;
### 1.1 docker compose&#13;
&#13;
`docker-compose.yml`&#13;
&#13;
```yaml&#13;
services:                                     &#13;
  jenkins:&#13;
    restart: always                            &#13;
    image: jenkins/jenkins:2.414.3  &#13;
    #image: jenkins/jenkins:2.387.2 &#13;
    container_name: jenkins&#13;
    network_mode: host&#13;
    ports:                                     &#13;
      - 18080:8080                              &#13;
      - 28888:28888&#13;
    volumes:&#13;
      - ./:/var/jenkins_home  &#13;
      - /usr/bin/docker:/usr/bin/docker               &#13;
      - /usr/local/bin/docker-compose:/usr/local/bin/docker-compose&#13;
      - /var/run/docker.sock:/var/run/docker.sock&#13;
    environment:&#13;
      - TZ=Asia/Shanghai&#13;
      - JENKINS_SLAVE_AGENT_PORT=28888&#13;
```&#13;
&#13;
## 2.Pipeline(流水线任务)&#13;
&#13;
### 2.1 Jenkinsfile概览&#13;
&#13;
*测试环境将服务部署到k8s中的Jenkinsfile，包括了项目代码拉取、配置文件拉取、项目编译、docker镜像构建/上传、多agent-workspace操作、Pod首次发布和滚动更新检测*&#13;
&#13;
```groovy&#13;
pipeline {&#13;
    agent {&#13;
        label 'node_X'&#13;
    }&#13;
    tools {&#13;
        jdk 'jdk11'&#13;
    }&#13;
    environment {&#13;
        //一般只需要修改这里几个&#13;
        CONTAINER_NAME = 'xxx'	//容器tag&#13;
        YAML_NAME = 'xxx-deploy.yml'	//yml文件名&#13;
        PUB_ENV = 'test'	//发布环境，对应以后进行版本控制的目录位置&#13;
        K8S_NAMESPACE = 'test-xxx'&#13;
        PROJECT_GIT_URL = ''       //项目代码地址&#13;
        CONFIG_GIT_URL = ''        //配置文件地址(当项目Jenkinsfile和项目不在同一仓库，这里指存放所有Jenkinsfile的仓库)&#13;
&#13;
        DOCKER_REGISTER_CREDS = credentials('registry_xxx')	//docker registry凭证&#13;
        DOCKER_REGISTRY = 'xxxxx'	//Docker仓库地址&#13;
        DOCKER_NAMESPACE = 'xxxxx'	//命名空间&#13;
        DOCKER_IMAGE = '${DOCKER_REGISTRY}/${DOCKER_NAMESPACE}/${CONTAINER_NAME}'	//组合成完整的镜像名称&#13;
    }&#13;
    stages {&#13;
        stage('get timestamp') {&#13;
            steps {&#13;
                script {&#13;
                    //获取当前时间戳&#13;
                    def timestamp = sh(returnStdout: true, script: 'date +%Y%m%d%H%M%S').trim()&#13;
                    //时间戳赋值&#13;
                    env.TIMESTAMP = timestamp&#13;
                }&#13;
            }&#13;
        }&#13;
        stage('fetch code') {&#13;
            steps {&#13;
                echo '----------Fetch code----------'&#13;
                git branch: 'release', credentialsId: 'git-credentials-backend', url: PROJECT_GIT_URL&#13;
            }&#13;
        }&#13;
        stage('fetch config') {&#13;
            agent {&#13;
                label 'node_xxx'	//在stage步骤中可以穿插在其他agent的操作步骤&#13;
            }&#13;
            steps {&#13;
                cleanWs() // 清理工作目录，防止工作目录产生其他产物&#13;
                dir('../jenkinsfile'){&#13;
                    echo '----------Fetch config----------'&#13;
                    git branch: 'master', credentialsId: 'git-credentials-backend', url: CONFIG_GIT_URL&#13;
                }&#13;
            }&#13;
        }&#13;
        stage('maven build'){&#13;
            steps {&#13;
                sh '/usr/local/maven3/bin/mvn -v'&#13;
                sh '/usr/local/maven3/bin/mvn clean package -Dmaven.test.skip=true -U'&#13;
            }&#13;
        }&#13;
        stage('docker build'){&#13;
            steps {&#13;
                sh '''&#13;
                    echo '当前时间为: ${env.TIMESTAMP}'&#13;
                    docker build -f ./Dockerfile -t ${DOCKER_IMAGE}:${env.TIMESTAMP} .&#13;
                '''&#13;
            }&#13;
        }&#13;
        stage('image push'){&#13;
            steps {&#13;
                sh '''&#13;
                    docker login -u ${DOCKER_REGISTER_CREDS_USR} -p=${DOCKER_REGISTER_CREDS_PSW} ${DOCKER_REGISTRY}&#13;
                    docker push ${DOCKER_IMAGE}:${env.TIMESTAMP}&#13;
                    docker rmi ${DOCKER_IMAGE}:${env.TIMESTAMP}&#13;
                '''&#13;
            }&#13;
        }&#13;
        stage('publish cn on k8s'){&#13;
            agent {&#13;
                label 'node_XXX'&#13;
            }&#13;
            steps {&#13;
                script {&#13;
                    // 运行kubectl命令，检查旧版本是否存在于集群中&#13;
                    def deploymentsName = 'bash -c 'kubectl get deployments -n ${K8S_NAMESPACE} ${CONTAINER_NAME} --output=jsonpath={.metadata.name}; exit 0;''&#13;
                    def result = sh(returnStdout: true, script: deploymentsName).trim()&#13;
                    echo '即将执行的服务: ${result}'&#13;
&#13;
                    if (result=='${CONTAINER_NAME}') {&#13;
                        // 旧版本已存在于集群中，执行kubectl set image更新镜像&#13;
                        echo '执行镜像滚动更新！'&#13;
                        sh '''&#13;
                            kubectl set image -n ${K8S_NAMESPACE} deployment/${CONTAINER_NAME} ${CONTAINER_NAME}=${DOCKER_IMAGE}:${env.TIMESTAMP} --record&#13;
                        '''&#13;
                    } else {&#13;
                        // 旧版本不存在于集群中，先执行kubectl apply部署&#13;
                        echo '服务不存在集群中，执行首次部署!'&#13;
                        sh '''&#13;
                            kubectl apply -f ../jenkinsfile/${PUB_ENV}/${K8S_NAMESPACE}/${YAML_NAME}&#13;
                            kubectl set image -n ${K8S_NAMESPACE} deployment/${CONTAINER_NAME} ${CONTAINER_NAME}=${DOCKER_IMAGE}:${env.TIMESTAMP} --record&#13;
                        '''&#13;
                    }&#13;
                }&#13;
            }&#13;
        }&#13;
        stage('Check Pod Status') {&#13;
            agent {&#13;
                label 'node_xxx'&#13;
            }&#13;
            steps {&#13;
                script {&#13;
                    def namespace = env.K8S_NAMESPACE&#13;
                    def containerName = env.CONTAINER_NAME&#13;
                    def timeoutSeconds = 120&#13;
&#13;
                    //等待滚动更新完成&#13;
                    sh 'kubectl rollout status deployment -n ${namespace} ${CONTAINER_NAME} --timeout=${timeoutSeconds}s'&#13;
                    sh 'sleep 5s'&#13;
                    // 获取Pod名称&#13;
                    def podName = sh(&#13;
                        script: 'kubectl get pods -l app=${containerName} -n ${namespace} -o jsonpath='{.items[0].metadata.name}'',&#13;
                        returnStdout: true&#13;
                    ).trim()&#13;
&#13;
                    // 检查容器状态&#13;
                    def containerReady = sh(&#13;
                        script: 'kubectl get pods ${podName} -n ${namespace} -o jsonpath='{.status.containerStatuses[0].ready}'',&#13;
                        returnStdout: true&#13;
                    ).trim()&#13;
&#13;
                    if (containerReady == 'true') {&#13;
                        echo 'Container ${containerName} in Pod ${podName} is ready. ContainerIsReady:${containerReady}'&#13;
                    } else {&#13;
                        error 'Container ${containerName} in Pod ${podName} is not ready. ContainerIsReady:${containerReady}'&#13;
                    }&#13;
                }&#13;
            }&#13;
        }&#13;
    }&#13;
}&#13;
&#13;
```&#13;
&#13;
### 2.2 镜像发布到K8S&#13;
&#13;
*见 2.1中 `publish cn on k8s`步骤*&#13;
&#13;
### 2.3 滚动更新/更新后检测&#13;
&#13;
*见 2.1 中 `Check Pod Status` 步骤*。</description><guid isPermaLink="true">https://blog.witter.top/post/Jenkins-Kubernetes-xiang-jie-he.html</guid><pubDate>Sat, 22 Jun 2024 15:59:09 +0000</pubDate></item><item><title>Openssl 升级</title><link>https://blog.witter.top/post/Openssl%20-sheng-ji.html</link><description>## 升级支持TLS 1.3&#13;
&#13;
```shell&#13;
# 下载&#13;
wget https://www.openssl.org/source/openssl-3.0.13.tar.gz&#13;
# 解压&#13;
tar -zxvf openssl-3.0.13.tar.gz&#13;
# 配置、编译&#13;
./config  --prefix=/usr/local/openssl&#13;
make&#13;
# 检查是否出错&#13;
make test&#13;
# 安装&#13;
make install&#13;
```&#13;
&#13;
安装完成后检查链接库是否正常，将缺少的文件直接软链接到系统的`/usr/lib64`目录下&#13;
&#13;
```shell&#13;
cd /usr/local/openssl/bin&#13;
ldd openssl&#13;
&#13;
linux-vdso.so.1 =&gt;  (0x00007ffe3893b000)&#13;
libssl.so.3 =&gt; not found&#13;
libcrypto.so.3 =&gt; not found&#13;
libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007ff49e5e0000)&#13;
libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007ff49e3c4000)&#13;
libc.so.6 =&gt; /lib64/libc.so.6 (0x00007ff49dff6000)&#13;
/lib64/ld-linux-x86-64.so.2 (0x00007ff49e7e4000)&#13;
&#13;
ln -s /usr/local/openssl/lib64/libssl.so.3 /usr/lib64/libssl.so.3&#13;
ln -s /usr/local/openssl/lib64/libcrypto.so.3 /usr/lib64/libcrypto.so.3&#13;
&#13;
linux-vdso.so.1 =&gt;  (0x00007fffd2ddb000)&#13;
libssl.so.3 =&gt; /lib64/libssl.so.3 (0x00007fbc48fc8000)&#13;
libcrypto.so.3 =&gt; /lib64/libcrypto.so.3 (0x00007fbc48954000)&#13;
libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fbc48750000)&#13;
libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fbc48534000)&#13;
libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fbc48166000)&#13;
/lib64/ld-linux-x86-64.so.2 (0x00007fbc4926d000)&#13;
```&#13;
&#13;
报错：&#13;
&#13;
```shell&#13;
Can't locate IPC/Cmd.pm in @INC (@INC contains: /home/sonkwo/openssl-3.0.13/util/perl /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 . /home/sonkwo/openssl-3.0.13/external/perl/Text-Template-1.56/lib) at /home/sonkwo/openssl-3.0.13/util/perl/OpenSSL/config.pm line 19.&#13;
BEGIN failed--compilation aborted at /home/sonkwo/openssl-3.0.13/util/perl/OpenSSL/config.pm line 19.&#13;
Compilation failed in require at /home/sonkwo/openssl-3.0.13/Configure line 23.&#13;
BEGIN failed--compilation aborted at /home/sonkwo/openssl-3.0.13/Configure line 23.&#13;
&#13;
yum install perl-IPC-Cmd&#13;
```&#13;
&#13;
。</description><guid isPermaLink="true">https://blog.witter.top/post/Openssl%20-sheng-ji.html</guid><pubDate>Thu, 20 Jun 2024 14:29:00 +0000</pubDate></item><item><title>Logrotate</title><link>https://blog.witter.top/post/Logrotate.html</link><description>logrotate 是一个 linux 系统日志的管理工具。</description><guid isPermaLink="true">https://blog.witter.top/post/Logrotate.html</guid><pubDate>Thu, 20 Jun 2024 14:27:25 +0000</pubDate></item><item><title>Kubernetes</title><link>https://blog.witter.top/post/Kubernetes.html</link><description>## 安装&#13;
&#13;
### 转发 IPv4 并让 iptables 看到桥接流量&#13;
&#13;
```shell&#13;
cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf&#13;
overlay&#13;
br_netfilter&#13;
EOF&#13;
&#13;
sudo modprobe overlay&#13;
sudo modprobe br_netfilter&#13;
&#13;
# 设置所需的 sysctl 参数，参数在重新启动后保持不变&#13;
cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf&#13;
net.bridge.bridge-nf-call-iptables  = 1&#13;
net.bridge.bridge-nf-call-ip6tables = 1&#13;
net.ipv4.ip_forward                 = 1&#13;
EOF&#13;
&#13;
# 应用 sysctl 参数而不重新启动&#13;
sudo sysctl --system&#13;
```&#13;
&#13;
通过运行以下指令确认 `br_netfilter` 和 `overlay` 模块被加载：&#13;
&#13;
```bash&#13;
lsmod | grep br_netfilter&#13;
lsmod | grep overlay&#13;
```&#13;
&#13;
通过运行以下指令确认 `net.bridge.bridge-nf-call-iptables`、`net.bridge.bridge-nf-call-ip6tables` 和 `net.ipv4.ip_forward` 系统变量在你的 `sysctl` 配置中被设置为 1：&#13;
&#13;
```bash&#13;
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward&#13;
```&#13;
&#13;
### 临时关闭swap分区&#13;
&#13;
```shell&#13;
sudo swapoff -a&#13;
# Debian永久关闭&#13;
systemctl --type swap --all&#13;
systemctl mask dev-xxx.swap&#13;
```&#13;
&#13;
### 配置cgroup驱动&#13;
&#13;
```shell&#13;
# 备份/etc/containerd/config.toml&#13;
containerd config default &gt; /etc/containerd/config.toml&#13;
&#13;
SystemdCgroup = true&#13;
&#13;
[plugins.'io.containerd.grpc.v1.cri']&#13;
  sandbox_image = 'registry.aliyuncs.com/google_containers/pause:3.6'&#13;
```&#13;
&#13;
### 安装 kubeadm、kubelet 和 kubectl&#13;
&#13;
```shell&#13;
# 基于Red Hat的发行版&#13;
# 将 SELinux 设置为 permissive 模式（相当于将其禁用）&#13;
sudo setenforce 0&#13;
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config&#13;
&#13;
# 此操作会覆盖 /etc/yum.repos.d/kubernetes.repo 中现存的所有配置&#13;
cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF&#13;
[kubernetes]&#13;
name=Kubernetes&#13;
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64&#13;
enabled=1&#13;
gpgcheck=0&#13;
repo_gpgcheck=0&#13;
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg&#13;
EOF&#13;
&#13;
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes&#13;
sudo systemctl enable --now kubelet&#13;
&#13;
# 基于Debian的发行版&#13;
sudo apt-get update&#13;
# apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包&#13;
sudo apt-get install -y apt-transport-https ca-certificates curl&#13;
&#13;
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg&#13;
&#13;
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list&#13;
&#13;
sudo apt-get update&#13;
sudo apt-get install -y kubelet kubeadm kubectl&#13;
sudo apt-mark hold kubelet kubeadm kubectl&#13;
```&#13;
&#13;
### 添加指令补全&#13;
&#13;
```shell&#13;
sudo apt-get install bash-completion&#13;
echo 'source &lt;(kubectl completion bash)' &gt;&gt; ~/.bashrc&#13;
source ~/.bashrc&#13;
cat ~/.bashrc&#13;
```&#13;
&#13;
&#13;
&#13;
### 初始化Master节点&#13;
&#13;
控制平面节点是运行控制平面组件的机器， 包括 etcd（集群数据库） 和 API 服务器 （命令行工具 kubectl 与之通信）。</description><guid isPermaLink="true">https://blog.witter.top/post/Kubernetes.html</guid><pubDate>Thu, 20 Jun 2024 14:19:12 +0000</pubDate></item><item><title>Linux 工具</title><link>https://blog.witter.top/post/Linux%20-gong-ju.html</link><description># Linux工具&#13;
&#13;
## psmisc&#13;
&#13;
psmisc 是一个 Linux 工具集，它提供了一些管理和监视进程的实用工具。</description><guid isPermaLink="true">https://blog.witter.top/post/Linux%20-gong-ju.html</guid><pubDate>Thu, 20 Jun 2024 13:51:19 +0000</pubDate></item><item><title>Helm 安装</title><link>https://blog.witter.top/post/Helm%20-an-zhuang.html</link><description>[官方文档](https://helm.sh/zh/docs/intro/install/)&#13;
&#13;
### 用二进制版本安装&#13;
&#13;
每个Helm [[版本](https://github.com/helm/helm/releases)](https://github.com/helm/helm/releases)都提供了各种操作系统的二进制版本，这些版本可以手动下载和安装。</description><guid isPermaLink="true">https://blog.witter.top/post/Helm%20-an-zhuang.html</guid><pubDate>Thu, 20 Jun 2024 13:36:36 +0000</pubDate></item><item><title>Hadoop</title><link>https://blog.witter.top/post/Hadoop.html</link><description>&#13;
## 1.Hadoop概述&#13;
&#13;
**核心组件**&#13;
&#13;
**HDFS**（分布式文件系统）：解决海量数据存储&#13;
&#13;
**YARN**（作业调度和集群资源管理的框架）：解决资源任务调度&#13;
&#13;
**MAPREDUCE**（分布式运算编程框架）：解决海量数据计算&#13;
&#13;
**其他框架**&#13;
&#13;
| **框架**  | **用途**                                                  |&#13;
| --------- | --------------------------------------------------------- |&#13;
| HDFS      | 分布式文件系统                                            |&#13;
| MapReduce | 分布式运算程序开发框架                                    |&#13;
| ZooKeeper | 分布式协调服务基础组件                                    |&#13;
| HIVE      | 基于HADOOP的分布式数据仓库，提供基于SQL的查询数据操作     |&#13;
| FLUME     | 日志数据采集框架                                          |&#13;
| oozie     | 工作流调度框架                                            |&#13;
| Sqoop     | 数据导入导出工具（比如用于mysql和HDFS之间）               |&#13;
| Impala    | 基于hive的实时sql查询分析                                 |&#13;
| Mahout    | 基于mapreduce/spark/flink等分布式运算框架的机器学习算法库 |&#13;
&#13;
**默认端口更改**&#13;
&#13;
1. 在hadoop3.x之前，多个Hadoop服务的默认端口都属于Linux的临时端口范围（32768-61000）。</description><guid isPermaLink="true">https://blog.witter.top/post/Hadoop.html</guid><pubDate>Thu, 20 Jun 2024 13:35:27 +0000</pubDate></item><item><title>CloudFlare搭建Docker镜像源</title><link>https://blog.witter.top/post/CloudFlare-da-jian-Docker-jing-xiang-yuan.html</link><description>&gt; [示例网站](https://docker.3mz.cloudns.ch/) 使用的 [教程](https://blog.lty520.faith/%E5%8D%9A%E6%96%87/%E8%87%AA%E5%BB%BAdocker-hub%E5%8A%A0%E9%80%9F%E9%95%9C%E5%83%8F) 和 [仓库](https://github.com/Doublemine/container-registry-worker)，对仓库代码进行了部分自定义修改&#13;
&#13;
`docker.ts`&#13;
&#13;
```typescript&#13;
import HTML from './docker.html';&#13;
&#13;
export default {&#13;
  async fetch(request: Request): Promise&lt;Response&gt; {&#13;
    const url = new URL(request.url);&#13;
    const path = url.pathname;&#13;
    const originalHost = request.headers.get('host');&#13;
    const registryHost = 'registry-1.docker.io';&#13;
&#13;
    if (path.startsWith('/v2/')) {&#13;
      const headers = new Headers(request.headers);&#13;
      headers.set('host', registryHost);&#13;
&#13;
      const registryUrl = `https://${registryHost}${path}`;&#13;
      const registryRequest = new Request(registryUrl, {&#13;
        method: request.method,&#13;
        headers: headers,&#13;
        body: request.body,&#13;
        redirect: 'follow', // 按照教程修改了这一行&#13;
      });&#13;
&#13;
      const registryResponse = await fetch(registryRequest);&#13;
&#13;
      const responseHeaders = new Headers(registryResponse.headers);&#13;
      responseHeaders.set('access-control-allow-origin', originalHost as string);&#13;
      responseHeaders.set('access-control-allow-headers', 'Authorization');&#13;
      return new Response(registryResponse.body, {&#13;
        status: registryResponse.status,&#13;
        statusText: registryResponse.statusText,&#13;
        headers: responseHeaders,&#13;
      });&#13;
    } else {&#13;
      return new Response(HTML.replace(/{{host}}/g, originalHost as string), {&#13;
        status: 200,&#13;
        headers: {&#13;
          'content-type': 'text/html'&#13;
        }&#13;
      });&#13;
    }&#13;
  }&#13;
}&#13;
```&#13;
&#13;
## 如何部署&#13;
&#13;
```shell&#13;
# 使用wrangler&#13;
wrangler publish --config wrangler-dockerhub.toml&#13;
```&#13;
&#13;
## 如何自定义域名&#13;
&#13;
访问CloudFlare后台 -&gt; Workers和Pages -&gt; 进入需要自定义的Worker -&gt; 设置 -&gt; 触发器 -&gt; 自定义域&#13;
&#13;
![image-20240620140432250](https://img.witter.top/file/519f26de32e9f4b53cc3b.png)。</description><guid isPermaLink="true">https://blog.witter.top/post/CloudFlare-da-jian-Docker-jing-xiang-yuan.html</guid><pubDate>Thu, 20 Jun 2024 06:05:28 +0000</pubDate></item><item><title>EFK日志系统</title><link>https://blog.witter.top/post/EFK-ri-zhi-xi-tong.html</link><description>&#13;
**注：现在新版本elastic stack已经支持将kafka作为输出和输入的目标**&#13;
&#13;
当日志不是结构化数据：*.log-&gt;filebeat-&gt;kafka-&gt;logstash-&gt;elasticsearch&#13;
&#13;
当日志是结构化数据：*.log-&gt;filebeat-&gt;kafka-&gt;filebeat-&gt;elasticsearch&#13;
&#13;
区别在于是否需要logstash进行日志的过滤和结构化；&#13;
&#13;
## 结构化日志&#13;
&#13;
**连接示例配置文件**&#13;
&#13;
### filebeat 1&#13;
&#13;
&gt; 此filebeat实例为日志采集端，即kafka生产者，可以有多个实例进行采集&#13;
&#13;
```yaml&#13;
filebeat.inputs:&#13;
- type: filestream #新版本常用文件流输入方式&#13;
  id: my-filestream-id #每个文件流输入必须有一个唯一的 ID。</description><guid isPermaLink="true">https://blog.witter.top/post/EFK-ri-zhi-xi-tong.html</guid><pubDate>Thu, 20 Jun 2024 03:26:28 +0000</pubDate></item><item><title>Azkaban</title><link>https://blog.witter.top/post/Azkaban.html</link><description>## 1.部署&#13;
&#13;
### 1.1 Solo&#13;
&#13;
独立服务器是Azkaban的独立实例，也是最简单的开始。</description><guid isPermaLink="true">https://blog.witter.top/post/Azkaban.html</guid><pubDate>Thu, 20 Jun 2024 02:47:18 +0000</pubDate></item><item><title>Certbot 申请SSL证书</title><link>https://blog.witter.top/post/Certbot%20-shen-qing-SSL-zheng-shu.html</link><description>## 官方网址&#13;
&#13;
https://certbot.eff.org/&#13;
&#13;
## 申请SSL证书&#13;
&#13;
&gt; 指定Nginx路径方法：&#13;
&gt;&#13;
&gt; 方式1： certbot --nginx    (当linux有多个版本nginx，会出现找错nginx的配置文件路径)&#13;
&gt;&#13;
&gt; 方式2： certbot --nginx-server-root  /usr/local/nginx/conf    (指定nginx的配置文件路径)&#13;
&#13;
1. 为单域名申请SSL证书&#13;
&#13;
   ```shell&#13;
   # 安装 certbot 以及 certbot nginx 插件&#13;
   sudo yum install certbot python2-certbot-nginx -y&#13;
   &#13;
   # 执行配置，中途会询问你的邮箱，如实填写即可&#13;
   sudo certbot --nginx&#13;
   &#13;
   # 自动续约&#13;
   sudo certbot renew --dry-run&#13;
   &#13;
   # 获得并安装一个证书。</description><guid isPermaLink="true">https://blog.witter.top/post/Certbot%20-shen-qing-SSL-zheng-shu.html</guid><pubDate>Thu, 20 Jun 2024 02:44:24 +0000</pubDate></item><item><title>V's first</title><link>https://blog.witter.top/post/V%27s%20first.html</link><description>&gt; 所做留下痕迹&#13;
&#13;
```&#13;
&gt; [!NOTE]&#13;
&gt; Useful information that users should know, even when skimming content.&#13;
&#13;
&gt; [!TIP]&#13;
&gt; Helpful advice for doing things better or more easily.&#13;
&#13;
&gt; [!IMPORTANT]&#13;
&gt; Key information users need to know to achieve their goal.&#13;
&#13;
&gt; [!WARNING]&#13;
&gt; Urgent info that needs immediate user attention to avoid problems.&#13;
&#13;
&gt; [!CAUTION]&#13;
&gt; Advises about risks or negative outcomes of certain actions.&#13;
```&#13;
&#13;
&gt; [!NOTE]&#13;
&gt; Useful information that users should know, even when skimming content.&#13;
&#13;
&gt; [!TIP]&#13;
&gt; Helpful advice for doing things better or more easily.&#13;
&#13;
&gt; [!IMPORTANT]&#13;
&gt; Key information users need to know to achieve their goal.&#13;
&#13;
&gt; [!WARNING]&#13;
&gt; Urgent info that needs immediate user attention to avoid problems.&#13;
&#13;
&gt; [!CAUTION]&#13;
&gt; Advises about risks or negative outcomes of certain actions.。</description><guid isPermaLink="true">https://blog.witter.top/post/V%27s%20first.html</guid><pubDate>Thu, 20 Jun 2024 02:19:02 +0000</pubDate></item><item><title>Python 小记</title><link>https://blog.witter.top/post/Python%20-xiao-ji.html</link><description>## 1.初识Python&#13;
&#13;
1989 年，作者决心开发一个新的解释程序&#13;
&#13;
1991年，第一个Python解释器诞生&#13;
&#13;
## 2.安装Python&#13;
&#13;
官网下载：https://www.python.org/downloads/&#13;
&#13;
- 添加到path&#13;
- 修改默认路径&#13;
&#13;
cmd 输入python&#13;
&#13;
```shell&#13;
C:\Users\Lenovo&gt;python&#13;
Python 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)] on win32&#13;
Type 'help', 'copyright', 'credits' or 'license' for more information.&#13;
&gt;&gt;&gt;&#13;
```&#13;
&#13;
**Python解释器**：用来翻译Python代码，并提交给计算机执行。</description><guid isPermaLink="true">https://blog.witter.top/post/Python%20-xiao-ji.html</guid><pubDate>Thu, 30 May 2024 11:27:27 +0000</pubDate></item><item><title>你觉得这是什么就是什么</title><link>https://blog.witter.top/post/ni-jue-de-zhe-shi-shen-me-jiu-shi-shen-me.html</link><description>[image](https://www.3mz.cloudns.ch/file/8859a6285fa21a73afc4c.jpg)&#13;
&lt;!-- ##{'timestamp':1705817030}## --&gt;。</description><guid isPermaLink="true">https://blog.witter.top/post/ni-jue-de-zhe-shi-shen-me-jiu-shi-shen-me.html</guid><pubDate>Sun, 21 Jan 2024 06:03:50 +0000</pubDate></item><item><title>About</title><link>https://blog.witter.top/about.html</link><description>- 人可以没有傲气，但不能没有傲骨；&#13;
- 兴趣是学习最好的老师；&#13;
&#13;
&#13;
&lt;span id='busuanzi'&gt;:robot:感谢第&lt;span&gt;&lt;/span&gt;小伙伴的&lt;span&gt;&lt;/span&gt;次访问此页面。</description><guid isPermaLink="true">https://blog.witter.top/about.html</guid><pubDate>Thu, 20 Jun 2024 14:43:02 +0000</pubDate></item><item><title>自存链接</title><link>https://blog.witter.top/link.html</link><description>- [图床](https://www.3mz.cloudns.ch)&#13;
- [短链](https://surl.witter.top)&#13;
- [监控](https://monit.witter.top)&#13;
- [丑丑头像生成器](https://txstc55.github.io/ugly-avatar)&#13;
- [People Die, but Long Live GitHub](https://laike9m.com/blog/people-die-but-long-live-github,122/)&#13;
&#13;
&lt;span id='busuanzi'&gt;:robot:感谢第&lt;span&gt;&lt;/span&gt;小伙伴的&lt;span&gt;&lt;/span&gt;次访问此页面。</description><guid isPermaLink="true">https://blog.witter.top/link.html</guid><pubDate>Fri, 21 Jun 2024 06:35:57 +0000</pubDate></item></channel></rss>