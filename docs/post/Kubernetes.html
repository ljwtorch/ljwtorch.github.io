<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://img.witter.top/file/b037878209903b7d5bb17.jpg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="## 安装

### 转发 IPv4 并让 iptables 看到桥接流量

```shell
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# 设置所需的 sysctl 参数，参数在重新启动后保持不变
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# 应用 sysctl 参数而不重新启动
sudo sysctl --system
```

通过运行以下指令确认 `br_netfilter` 和 `overlay` 模块被加载：

```bash
lsmod | grep br_netfilter
lsmod | grep overlay
```

通过运行以下指令确认 `net.bridge.bridge-nf-call-iptables`、`net.bridge.bridge-nf-call-ip6tables` 和 `net.ipv4.ip_forward` 系统变量在你的 `sysctl` 配置中被设置为 1：

```bash
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

### 临时关闭swap分区

```shell
sudo swapoff -a
# Debian永久关闭
systemctl --type swap --all
systemctl mask dev-xxx.swap
```

### 配置cgroup驱动

```shell
# 备份/etc/containerd/config.toml
containerd config default > /etc/containerd/config.toml

SystemdCgroup = true

[plugins.'io.containerd.grpc.v1.cri']
  sandbox_image = 'registry.aliyuncs.com/google_containers/pause:3.6'
```

### 安装 kubeadm、kubelet 和 kubectl

```shell
# 基于Red Hat的发行版
# 将 SELinux 设置为 permissive 模式（相当于将其禁用）
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# 此操作会覆盖 /etc/yum.repos.d/kubernetes.repo 中现存的所有配置
cat > /etc/yum.repos.d/kubernetes.repo << EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
sudo systemctl enable --now kubelet

# 基于Debian的发行版
sudo apt-get update
# apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包
sudo apt-get install -y apt-transport-https ca-certificates curl

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

### 添加指令补全

```shell
sudo apt-get install bash-completion
echo 'source <(kubectl completion bash)' >> ~/.bashrc
source ~/.bashrc
cat ~/.bashrc
```



### 初始化Master节点

控制平面节点是运行控制平面组件的机器， 包括 etcd（集群数据库） 和 API 服务器 （命令行工具 kubectl 与之通信）。">
<meta property="og:title" content="Kubernetes">
<meta property="og:description" content="## 安装

### 转发 IPv4 并让 iptables 看到桥接流量

```shell
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# 设置所需的 sysctl 参数，参数在重新启动后保持不变
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# 应用 sysctl 参数而不重新启动
sudo sysctl --system
```

通过运行以下指令确认 `br_netfilter` 和 `overlay` 模块被加载：

```bash
lsmod | grep br_netfilter
lsmod | grep overlay
```

通过运行以下指令确认 `net.bridge.bridge-nf-call-iptables`、`net.bridge.bridge-nf-call-ip6tables` 和 `net.ipv4.ip_forward` 系统变量在你的 `sysctl` 配置中被设置为 1：

```bash
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```

### 临时关闭swap分区

```shell
sudo swapoff -a
# Debian永久关闭
systemctl --type swap --all
systemctl mask dev-xxx.swap
```

### 配置cgroup驱动

```shell
# 备份/etc/containerd/config.toml
containerd config default > /etc/containerd/config.toml

SystemdCgroup = true

[plugins.'io.containerd.grpc.v1.cri']
  sandbox_image = 'registry.aliyuncs.com/google_containers/pause:3.6'
```

### 安装 kubeadm、kubelet 和 kubectl

```shell
# 基于Red Hat的发行版
# 将 SELinux 设置为 permissive 模式（相当于将其禁用）
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

# 此操作会覆盖 /etc/yum.repos.d/kubernetes.repo 中现存的所有配置
cat > /etc/yum.repos.d/kubernetes.repo << EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
sudo systemctl enable --now kubelet

# 基于Debian的发行版
sudo apt-get update
# apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包
sudo apt-get install -y apt-transport-https ca-certificates curl

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```

### 添加指令补全

```shell
sudo apt-get install bash-completion
echo 'source <(kubectl completion bash)' >> ~/.bashrc
source ~/.bashrc
cat ~/.bashrc
```



### 初始化Master节点

控制平面节点是运行控制平面组件的机器， 包括 etcd（集群数据库） 和 API 服务器 （命令行工具 kubectl 与之通信）。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://blog.witter.top/post/Kubernetes.html">
<meta property="og:image" content="https://img.witter.top/file/b037878209903b7d5bb17.jpg">
<title>Kubernetes</title>
<link href="//unpkg.com/@wooorm/starry-night@2.1.1/style/both.css" rel="stylesheet" />


</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">Kubernetes</h1>
<div class="title-right">
    <a href="https://blog.witter.top" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/ljwtorch/ljwtorch.github.io/issues/9" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><h2>安装</h2>
<h3>转发 IPv4 并让 iptables 看到桥接流量</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">cat <span class="pl-s"><span class="pl-k">&lt;&lt;</span><span class="pl-k">EOF</span> | sudo tee /etc/modules-load.d/k8s.conf</span>
<span class="pl-s">overlay</span>
<span class="pl-s">br_netfilter</span>
<span class="pl-s"><span class="pl-k">EOF</span></span>

sudo modprobe overlay
sudo modprobe br_netfilter

<span class="pl-c"><span class="pl-c">#</span> 设置所需的 sysctl 参数，参数在重新启动后保持不变</span>
cat <span class="pl-s"><span class="pl-k">&lt;&lt;</span><span class="pl-k">EOF</span> | sudo tee /etc/sysctl.d/k8s.conf</span>
<span class="pl-s">net.bridge.bridge-nf-call-iptables  = 1</span>
<span class="pl-s">net.bridge.bridge-nf-call-ip6tables = 1</span>
<span class="pl-s">net.ipv4.ip_forward                 = 1</span>
<span class="pl-s"><span class="pl-k">EOF</span></span>

<span class="pl-c"><span class="pl-c">#</span> 应用 sysctl 参数而不重新启动</span>
sudo sysctl --system</pre></div>
<p>通过运行以下指令确认 <code class="notranslate">br_netfilter</code> 和 <code class="notranslate">overlay</code> 模块被加载：</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">lsmod <span class="pl-k">|</span> grep br_netfilter
lsmod <span class="pl-k">|</span> grep overlay</pre></div>
<p>通过运行以下指令确认 <code class="notranslate">net.bridge.bridge-nf-call-iptables</code>、<code class="notranslate">net.bridge.bridge-nf-call-ip6tables</code> 和 <code class="notranslate">net.ipv4.ip_forward</code> 系统变量在你的 <code class="notranslate">sysctl</code> 配置中被设置为 1：</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward</pre></div>
<h3>临时关闭swap分区</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">sudo swapoff -a
<span class="pl-c"><span class="pl-c">#</span> Debian永久关闭</span>
systemctl --type swap --all
systemctl mask dev-xxx.swap</pre></div>
<h3>配置cgroup驱动</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 备份/etc/containerd/config.toml</span>
containerd config default <span class="pl-k">&gt;</span> /etc/containerd/config.toml

SystemdCgroup = <span class="pl-c1">true</span>

[plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>]
  sandbox_image = <span class="pl-s"><span class="pl-pds">"</span>registry.aliyuncs.com/google_containers/pause:3.6<span class="pl-pds">"</span></span></pre></div>
<h3>安装 kubeadm、kubelet 和 kubectl</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 基于Red Hat的发行版</span>
<span class="pl-c"><span class="pl-c">#</span> 将 SELinux 设置为 permissive 模式（相当于将其禁用）</span>
sudo setenforce 0
sudo sed -i <span class="pl-s"><span class="pl-pds">'</span>s/^SELINUX=enforcing$/SELINUX=permissive/<span class="pl-pds">'</span></span> /etc/selinux/config

<span class="pl-c"><span class="pl-c">#</span> 此操作会覆盖 /etc/yum.repos.d/kubernetes.repo 中现存的所有配置</span>
cat <span class="pl-k">&gt;</span> /etc/yum.repos.d/kubernetes.repo <span class="pl-s"><span class="pl-k">&lt;&lt;</span> <span class="pl-k">EOF</span></span>
<span class="pl-s">[kubernetes]</span>
<span class="pl-s">name=Kubernetes</span>
<span class="pl-s">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span>
<span class="pl-s">enabled=1</span>
<span class="pl-s">gpgcheck=0</span>
<span class="pl-s">repo_gpgcheck=0</span>
<span class="pl-s">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span>
<span class="pl-s"><span class="pl-k">EOF</span></span>

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
sudo systemctl <span class="pl-c1">enable</span> --now kubelet

<span class="pl-c"><span class="pl-c">#</span> 基于Debian的发行版</span>
sudo apt-get update
<span class="pl-c"><span class="pl-c">#</span> apt-transport-https 可能是一个虚拟包（dummy package）；如果是的话，你可以跳过安装这个包</span>
sudo apt-get install -y apt-transport-https ca-certificates curl

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key <span class="pl-k">|</span> sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

<span class="pl-c1">echo</span> <span class="pl-s"><span class="pl-pds">'</span>deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /<span class="pl-pds">'</span></span> <span class="pl-k">|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl</pre></div>
<h3>添加指令补全</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">sudo apt-get install bash-completion
<span class="pl-c1">echo</span> <span class="pl-s"><span class="pl-pds">"</span>source &lt;(kubectl completion bash)<span class="pl-pds">"</span></span> <span class="pl-k">&gt;&gt;</span> <span class="pl-k">~</span>/.bashrc
<span class="pl-c1">source</span> <span class="pl-k">~</span>/.bashrc
cat <span class="pl-k">~</span>/.bashrc</pre></div>
<h3>初始化Master节点</h3>
<p>控制平面节点是运行控制平面组件的机器， 包括 etcd（集群数据库） 和 API 服务器 （命令行工具 kubectl 与之通信）。</p>
<ol>
<li>如果计划将单个控制平面 kubeadm 集群升级成高可用， 你应该指定 <code class="notranslate">--control-plane-endpoint</code> 为所有控制平面节点设置共享端点。 端点可以是负载均衡器的 DNS 名称或 IP 地址。</li>
<li>选择一个 Pod 网络插件，并验证是否需要为 kubeadm init 传递参数。 根据你选择的网络插件，你需要设置 --pod-network-cidr 的值。</li>
<li><code class="notranslate">--apiserver-advertise-address</code>选项用于指定API服务器（kube-apiserver）公开给集群成员的地址，它指定了Master节点上kube-apiserver进程所使用的网络地址，用于与其他节点和客户端通信。</li>
</ol>
<div class="highlight highlight-source-shell"><pre class="notranslate">sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers --apiserver-advertise-address=10.1.1.33 --control-plane-endpoint=10.1.1.33 --pod-network-cidr=192.168.0.0/16

sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers --apiserver-advertise-address=10.1.1.33 --control-plane-endpoint=10.1.1.33 --pod-network-cidr=10.244.0.0/16
sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers --apiserver-advertise-address=192.168.8.99 --control-plane-endpoint=192.168.8.99 --pod-network-cidr=10.2.0.0/16</pre></div>
<div class="highlight highlight-source-shell"><pre class="notranslate">[init] Using Kubernetes version: v1.27.1
[preflight] Running pre-flight checks
[preflight] Pulling images required <span class="pl-k">for</span> setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action <span class="pl-k">in</span> beforehand using <span class="pl-s"><span class="pl-pds">'</span>kubeadm config images pull<span class="pl-pds">'</span></span>
W0417 13:53:10.500146  787361 images.go:80] could not find officially supported version of etcd <span class="pl-k">for</span> Kubernetes v1.27.1, falling back to the nearest etcd version (3.5.7-0)
W0417 13:53:10.689988  787361 checks.go:835] detected that the sandbox image <span class="pl-s"><span class="pl-pds">"</span>registry.k8s.io/pause:3.6<span class="pl-pds">"</span></span> of the container runtime is inconsistent with that used by kubeadm. It is recommended that using <span class="pl-s"><span class="pl-pds">"</span>registry.aliyuncs.com/google_containers/pause:3.9<span class="pl-pds">"</span></span> as the CRI sandbox image.
[certs] Using certificateDir folder <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes/pki<span class="pl-pds">"</span></span>
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>ca<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>apiserver<span class="pl-pds">"</span></span> certificate and key
[certs] apiserver serving cert is signed <span class="pl-k">for</span> DNS names [dev-33 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.1.1.33]
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>apiserver-kubelet-client<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>front-proxy-ca<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>front-proxy-client<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>etcd/ca<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>etcd/server<span class="pl-pds">"</span></span> certificate and key
[certs] etcd/server serving cert is signed <span class="pl-k">for</span> DNS names [dev-33 localhost] and IPs [10.1.1.33 127.0.0.1 ::1]
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>etcd/peer<span class="pl-pds">"</span></span> certificate and key
[certs] etcd/peer serving cert is signed <span class="pl-k">for</span> DNS names [dev-33 localhost] and IPs [10.1.1.33 127.0.0.1 ::1]
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>etcd/healthcheck-client<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>apiserver-etcd-client<span class="pl-pds">"</span></span> certificate and key
[certs] Generating <span class="pl-s"><span class="pl-pds">"</span>sa<span class="pl-pds">"</span></span> key and public key
[kubeconfig] Using kubeconfig folder <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes<span class="pl-pds">"</span></span>
[kubeconfig] Writing <span class="pl-s"><span class="pl-pds">"</span>admin.conf<span class="pl-pds">"</span></span> kubeconfig file
[kubeconfig] Writing <span class="pl-s"><span class="pl-pds">"</span>kubelet.conf<span class="pl-pds">"</span></span> kubeconfig file
[kubeconfig] Writing <span class="pl-s"><span class="pl-pds">"</span>controller-manager.conf<span class="pl-pds">"</span></span> kubeconfig file
[kubeconfig] Writing <span class="pl-s"><span class="pl-pds">"</span>scheduler.conf<span class="pl-pds">"</span></span> kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file <span class="pl-s"><span class="pl-pds">"</span>/var/lib/kubelet/kubeadm-flags.env<span class="pl-pds">"</span></span>
[kubelet-start] Writing kubelet configuration to file <span class="pl-s"><span class="pl-pds">"</span>/var/lib/kubelet/config.yaml<span class="pl-pds">"</span></span>
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes/manifests<span class="pl-pds">"</span></span>
[control-plane] Creating static Pod manifest <span class="pl-k">for</span> <span class="pl-s"><span class="pl-pds">"</span>kube-apiserver<span class="pl-pds">"</span></span>
[control-plane] Creating static Pod manifest <span class="pl-k">for</span> <span class="pl-s"><span class="pl-pds">"</span>kube-controller-manager<span class="pl-pds">"</span></span>
[control-plane] Creating static Pod manifest <span class="pl-k">for</span> <span class="pl-s"><span class="pl-pds">"</span>kube-scheduler<span class="pl-pds">"</span></span>
[etcd] Creating static Pod manifest <span class="pl-k">for</span> <span class="pl-smi">local etcd</span> <span class="pl-k">in</span> <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes/manifests<span class="pl-pds">"</span></span>
W0417 13:53:18.875118  787361 images.go:80] could not find officially supported version of etcd <span class="pl-k">for</span> Kubernetes v1.27.1, falling back to the nearest etcd version (3.5.7-0)
[wait-control-plane] Waiting <span class="pl-k">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes/manifests<span class="pl-pds">"</span></span>. This can take up to 4m0s
[apiclient] All control plane components are healthy after 7.003124 seconds
[upload-config] Storing the configuration used <span class="pl-k">in</span> ConfigMap <span class="pl-s"><span class="pl-pds">"</span>kubeadm-config<span class="pl-pds">"</span></span> <span class="pl-k">in</span> the <span class="pl-s"><span class="pl-pds">"</span>kube-system<span class="pl-pds">"</span></span> Namespace
[kubelet] Creating a ConfigMap <span class="pl-s"><span class="pl-pds">"</span>kubelet-config<span class="pl-pds">"</span></span> <span class="pl-k">in</span> namespace kube-system with the configuration <span class="pl-k">for</span> <span class="pl-smi">the kubelets</span> <span class="pl-k">in</span> the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node dev-33 as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
[mark-control-plane] Marking the node dev-33 as control-plane by adding the taints [node-role.kubernetes.io/control-plane:NoSchedule]
[bootstrap-token] Using token: vxma82.htnutqlrk5ogk4jt
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="pl-k">in</span> order <span class="pl-k">for</span> nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation <span class="pl-k">for</span> <span class="pl-smi">all node client certificates</span> <span class="pl-k">in</span> the cluster
[bootstrap-token] Creating the <span class="pl-s"><span class="pl-pds">"</span>cluster-info<span class="pl-pds">"</span></span> ConfigMap <span class="pl-k">in</span> the <span class="pl-s"><span class="pl-pds">"</span>kube-public<span class="pl-pds">"</span></span> namespace
[kubelet-finalize] Updating <span class="pl-s"><span class="pl-pds">"</span>/etc/kubernetes/kubelet.conf<span class="pl-pds">"</span></span> to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully<span class="pl-k">!</span>

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span class="pl-smi">$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span class="pl-smi">$HOME</span>/.kube/config
  sudo chown <span class="pl-s"><span class="pl-pds">$(</span>id -u<span class="pl-pds">)</span></span>:<span class="pl-s"><span class="pl-pds">$(</span>id -g<span class="pl-pds">)</span></span> <span class="pl-smi">$HOME</span>/.kube/config

Alternatively, <span class="pl-k">if</span> you are the root user, you can run:

  <span class="pl-k">export</span> KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run <span class="pl-s"><span class="pl-pds">"</span>kubectl apply -f [podnetwork].yaml<span class="pl-pds">"</span></span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and <span class="pl-k">then</span> running the following as root:

  kubeadm join 10.1.1.33:6443 --token vxma82.htnutqlrk5ogk4jt \
        --discovery-token-ca-cert-hash sha256:a33deba545a4ea70d612cd828954d3c8c33e8554a2763d5148f587e5c29830bd \
        --control-plane 

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.1.1.33:6443 --token vxma82.htnutqlrk5ogk4jt \
        --discovery-token-ca-cert-hash sha256:a33deba545a4ea70d612cd828954d3c8c33e8554a2763d5148f587e5c29830bd </pre></div>
<h3>部署Node节点</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">kubeadm join 10.1.1.33:6443 --token n826db.gaagqa112dpjbs0p \
        --discovery-token-ca-cert-hash sha256:3a93c6c6c752ee40dfd8e5e9be8bd442ee350b5114bc9ec16cede4c234b656d7 </pre></div>
<h3>排查指令</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">journalctl -xefu kubelet
journalctl -xefu containerd</pre></div>
<h3>Ingress控制器</h3>
<p>Ingress 公开从集群外部到集群内服务的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0e51daa664627de7cb52d236b50ac9b1b365fb7cf280c490ccf2b0a7273d47ad/68747470733a2f2f696d672e7769747465722e746f702f66696c652f3266363266623030383734666638343932396333662e706e67"><img src="https://camo.githubusercontent.com/0e51daa664627de7cb52d236b50ac9b1b365fb7cf280c490ccf2b0a7273d47ad/68747470733a2f2f696d672e7769747465722e746f702f66696c652f3266363266623030383734666638343932396333662e706e67" alt="image-20230506111157764" data-canonical-src="https://img.witter.top/file/2f62fb00874ff84929c3f.png" style="max-width: 100%; height: auto;"></a></p>
<h3>添加kuboard</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">docker run -d \
  --restart=unless-stopped \
  --name=kuboard \
  -p 80:80/tcp \
  -p 10081:10081/tcp \
  -v ./:/data \
  -e KUBOARD_LOGIN_TYPE=<span class="pl-s"><span class="pl-pds">"</span>ldap<span class="pl-pds">"</span></span> \
  -e KUBOARD_ENDPOINT=<span class="pl-s"><span class="pl-pds">"</span>http://10.1.1.33:80<span class="pl-pds">"</span></span> \
  -e KUBOARD_AGENT_SERVER_TCP_PORT=<span class="pl-s"><span class="pl-pds">"</span>10081<span class="pl-pds">"</span></span> \
  -e KUBOARD_ROOT_USER=<span class="pl-s"><span class="pl-pds">"</span>xxxxx<span class="pl-pds">"</span></span> \
  -e LDAP_HOST=<span class="pl-s"><span class="pl-pds">"</span>ipa.xxxxxx.cn:636<span class="pl-pds">"</span></span> \
  -e LDAP_SKIP_SSL_VERIFY=<span class="pl-s"><span class="pl-pds">"</span>false<span class="pl-pds">"</span></span> \
  -e LDAP_BIND_DN=<span class="pl-s"><span class="pl-pds">"</span>uid=xxx,cn=users,cn=accounts,dc=xxx,dc=cn<span class="pl-pds">"</span></span> \
  -e LDAP_BIND_PASSWORD=<span class="pl-s"><span class="pl-pds">"</span>xxxxxxxx<span class="pl-pds">"</span></span> \
  -e LDAP_BASE_DN=<span class="pl-s"><span class="pl-pds">"</span>dc=xxxxxx,dc=cn<span class="pl-pds">"</span></span> \
  -e LDAP_FILTER=<span class="pl-s"><span class="pl-pds">"</span>(uid=%(user)s)<span class="pl-pds">"</span></span> \
  -e LDAP_ID_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>uid<span class="pl-pds">"</span></span> \
  -e LDAP_USER_NAME_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>uid<span class="pl-pds">"</span></span> \
  -e LDAP_EMAIL_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>mail<span class="pl-pds">"</span></span> \
  -e LDAP_DISPLAY_NAME_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>displayname<span class="pl-pds">"</span></span> \
  -e LDAP_GROUP_SEARCH_BASE_DN=<span class="pl-s"><span class="pl-pds">"</span>cn=groups,cn=accounts,dc=xxx,dc=cn<span class="pl-pds">"</span></span> \
  -e LDAP_GROUP_SEARCH_FILTER=<span class="pl-s"><span class="pl-pds">"</span>(objectClass=groupOfNames)<span class="pl-pds">"</span></span> \
  -e LDAP_USER_MACHER_USER_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>memberOf<span class="pl-pds">"</span></span> \
  -e LDAP_USER_MACHER_GROUP_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>member<span class="pl-pds">"</span></span> \
  -e LDAP_GROUP_NAME_ATTRIBUTE=<span class="pl-s"><span class="pl-pds">"</span>cn<span class="pl-pds">"</span></span> \
  eipwork/kuboard:v3</pre></div>
<h2>管理后续节点</h2>
<h3>添加master节点</h3>
<p>调整ectd为单节点模式</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">etcd 启动失败是由于 etcd 在 3 节点集群模式在启动却无法连接另外 2 台 master 节点的 etcd ，要解决这个问题需要改为单节点集群模式。开始不知道如何将 etcd 改为单节点模式，后来在网上找到 2 个参数 --initial-cluster-state=new 与 --force-new-cluster ，在 /etc/kubernetes/manifests/etcd.yaml 中给 etcd 命令加上这 2 个参数，并重启服务器后，master 节点就能正常运行了。</pre></div>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 获取token和token证书</span>
kubeadm token create --print-join-command 

kubeadm join 10.1.1.33:6443 --token py3msf.sy2inpdw1z17247r --discovery-token-ca-cert-hash sha256:be0a7aa7640f735c57c3d282453f4fc047804feee6be68b7604267b8149bdbc7 

<span class="pl-c"><span class="pl-c">#</span> 获取control-plane证书</span>
sudo kubeadm init phase upload-certs --upload-certs
I0907 14:19:25.567659 2491954 version.go:256] remote version is much newer: v1.28.1<span class="pl-k">;</span> falling back to: stable-1.27
[upload-certs] Storing the certificates <span class="pl-k">in</span> Secret <span class="pl-s"><span class="pl-pds">"</span>kubeadm-certs<span class="pl-pds">"</span></span> <span class="pl-k">in</span> the <span class="pl-s"><span class="pl-pds">"</span>kube-system<span class="pl-pds">"</span></span> Namespace
[upload-certs] Using certificate key:
abb6b151b79156887cb415c7fd3b3af653b4b26f4da3c6dfb93c3d7c41b25867

<span class="pl-c"><span class="pl-c">#</span> master节点执行命令</span>
sudo kubeadm join 192.168.255.100:6443 --token peawzl.bwonk5nviow72m9g \
--discovery-token-ca-cert-hash sha256:be0a7aa7640f735c57c3d282453f4fc047804feee6be68b7604267b8149bdbc7 \
--control-plane --certificate-key abb6b151b79156887cb415c7fd3b3af653b4b26f4da3c6dfb93c3d7c41b25867

</pre></div>
<h3>添加node节点</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 获取master节点的join token</span>
kubeadm token create --print-join-command 

kubeadm join 10.1.1.33:6443 --token py3msf.sy2inpdw1z17247r --discovery-token-ca-cert-hash sha256:be0a7aa7640f735c57c3d282453f4fc047804feee6be68b7604267b8149bdbc7 

<span class="pl-c"><span class="pl-c">#</span> 在Node节点上执行join指令</span></pre></div>
<h3>给node节点打标签</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 获取节点详情</span>
kubectl get nodes -o wide --show-labels=true
<span class="pl-c"><span class="pl-c">#</span> 添加节点标签</span>
kubectl label nodes xxxx labelname=labelvalue

<span class="pl-c"><span class="pl-c">#</span> 使用nodeselector进行pod的调度</span></pre></div>
<h3>使POD调度到Master节点</h3>
<p>在部署yaml文件中添加能够容忍的污点配置</p>
<p><code class="notranslate">kubectl describe node bj-8-105</code>使用该指令找到Taints字段填充下方yaml配置中的key</p>
<div class="highlight highlight-source-yaml"><pre class="notranslate">    <span class="pl-ent">spec</span>:
      <span class="pl-ent">tolerations</span>:
      - <span class="pl-ent">effect</span>: <span class="pl-s">NoSchedule</span>
        <span class="pl-ent">key</span>: <span class="pl-s">node-role.kubernetes.io/control-plane</span></pre></div>
<h2>配置解释</h2>
<h3>Service</h3>
<ul>
<li>port：集群内服务访问的service入口，service暴露在Cluster上的端口；集群内部节点可以通过该端口访问该服务，但是外部网络不能够访问到服务；</li>
<li>targetPort：容器的端口，最底层服务提供的端口，相当于pod的端口；从port或者nodePort进入的流量，经过路由转发之后最终都会通过targetPort进入到pod中；</li>
</ul>
<div class="highlight highlight-source-shell"><pre class="notranslate">apiVersion: v1
kind: Service
metadata:
  name: xxx-community-frontend-hk
spec:
  type: NodePort
  selector:
    app: xxx-community-frontend-hk
  ports:
    <span class="pl-c"><span class="pl-c">#</span> 默认情况下，为了方便起见，`targetPort` 被设置为与 `port` 字段相同的值。</span>
  - nodePort: 30003	<span class="pl-c"><span class="pl-c">#</span> 外部访问的端口</span>
    port: 3230		<span class="pl-c"><span class="pl-c">#</span> 容器间，服务调用的端口</span>
    protocol: TCP	<span class="pl-c"><span class="pl-c">#</span> 协议</span>
    targetPort: 3230# 容器暴露的端口，与Dockerfile暴露端口保持一致</pre></div>
<h3>Deployment</h3>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> yaml格式的pod定义文件完整内容：</span>
<span class="pl-ent">apiVersion</span>: <span class="pl-c1">v1</span>       <span class="pl-c"><span class="pl-c">#</span>必选，版本号，例如v1</span>
<span class="pl-ent">kind</span>: <span class="pl-s">Pod       </span><span class="pl-c"><span class="pl-c">#</span>必选，Pod</span>
<span class="pl-ent">metadata</span>:       <span class="pl-c"><span class="pl-c">#</span>必选，元数据</span>
  <span class="pl-ent">name</span>: <span class="pl-s">string       </span><span class="pl-c"><span class="pl-c">#</span>必选，Pod名称</span>
  <span class="pl-ent">namespace</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>必选，Pod所属的命名空间</span>
  <span class="pl-ent">labels</span>:      <span class="pl-c"><span class="pl-c">#</span>自定义标签</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>自定义标签名字</span>
  <span class="pl-ent">annotations</span>:       <span class="pl-c"><span class="pl-c">#</span>自定义注释列表</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string</span>
<span class="pl-ent">spec</span>:         <span class="pl-c"><span class="pl-c">#</span>必选，Pod中容器的详细定义</span>
  <span class="pl-ent">containers</span>:      <span class="pl-c"><span class="pl-c">#</span>必选，Pod中容器列表</span>
  - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>必选，容器名称</span>
    <span class="pl-ent">image</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>必选，容器的镜像名称</span>
    <span class="pl-ent">imagePullPolicy</span>: <span class="pl-s">[Always | Never | IfNotPresent] </span><span class="pl-c"><span class="pl-c">#</span>获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像</span>
    <span class="pl-ent">command</span>: <span class="pl-s">[string]    </span><span class="pl-c"><span class="pl-c">#</span>容器的启动命令列表，如不指定，使用打包时使用的启动命令</span>
    <span class="pl-ent">args</span>: <span class="pl-s">[string]     </span><span class="pl-c"><span class="pl-c">#</span>容器的启动命令参数列表</span>
    <span class="pl-ent">workingDir</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>容器的工作目录</span>
    <span class="pl-ent">volumeMounts</span>:    <span class="pl-c"><span class="pl-c">#</span>挂载到容器内部的存储卷配置</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名</span>
      <span class="pl-ent">mountPath</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>存储卷在容器内mount的绝对路径，应少于512字符</span>
      <span class="pl-ent">readOnly</span>: <span class="pl-s">boolean    </span><span class="pl-c"><span class="pl-c">#</span>是否为只读模式</span>
    <span class="pl-ent">ports</span>:       <span class="pl-c"><span class="pl-c">#</span>需要暴露的端口库号列表</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>端口号名称</span>
      <span class="pl-ent">containerPort</span>: <span class="pl-s">int   </span><span class="pl-c"><span class="pl-c">#</span>容器需要监听的端口号</span>
      <span class="pl-ent">hostPort</span>: <span class="pl-s">int    </span><span class="pl-c"><span class="pl-c">#</span>容器所在主机需要监听的端口号，默认与Container相同</span>
      <span class="pl-ent">protocol</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>端口协议，支持TCP和UDP，默认TCP</span>
    <span class="pl-ent">env</span>:       <span class="pl-c"><span class="pl-c">#</span>容器运行前需设置的环境变量列表</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>环境变量名称</span>
      <span class="pl-ent">value</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>环境变量的值</span>
    <span class="pl-ent">resources</span>:       <span class="pl-c"><span class="pl-c">#</span>资源限制和请求的设置</span>
      <span class="pl-ent">limits</span>:      <span class="pl-c"><span class="pl-c">#</span>资源限制的设置</span>
        <span class="pl-ent">cpu</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>Cpu的限制，单位为core数，将用于docker run --cpu-shares参数</span>
        <span class="pl-ent">memory</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>内存限制，单位可以为Mib/Gib，将用于docker run --memory参数</span>
      <span class="pl-ent">requests</span>:      <span class="pl-c"><span class="pl-c">#</span>资源请求的设置</span>
        <span class="pl-ent">cpu</span>: <span class="pl-s">string    </span><span class="pl-c"><span class="pl-c">#</span>Cpu请求，容器启动的初始可用数量</span>
        <span class="pl-ent">memory</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>内存清楚，容器启动的初始可用数量</span>
    <span class="pl-ent">livenessProbe</span>:     <span class="pl-c"><span class="pl-c">#</span>对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可</span>
      <span class="pl-ent">exec</span>:      <span class="pl-c"><span class="pl-c">#</span>对Pod容器内检查方式设置为exec方式</span>
        <span class="pl-ent">command</span>: <span class="pl-s">[string]  </span><span class="pl-c"><span class="pl-c">#</span>exec方式需要制定的命令或脚本</span>
      <span class="pl-ent">httpGet</span>:       <span class="pl-c"><span class="pl-c">#</span>对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port</span>
        <span class="pl-ent">path</span>: <span class="pl-s">string</span>
        <span class="pl-ent">port</span>: <span class="pl-s">number</span>
        <span class="pl-ent">host</span>: <span class="pl-s">string</span>
        <span class="pl-ent">scheme</span>: <span class="pl-s">string</span>
        <span class="pl-ent">HttpHeaders</span>:
        - <span class="pl-ent">name</span>: <span class="pl-s">string</span>
          <span class="pl-ent">value</span>: <span class="pl-s">string</span>
      <span class="pl-ent">tcpSocket</span>:     <span class="pl-c"><span class="pl-c">#</span>对Pod内个容器健康检查方式设置为tcpSocket方式</span>
         <span class="pl-ent">port</span>: <span class="pl-s">number</span>
       <span class="pl-ent">initialDelaySeconds</span>: <span class="pl-c1">0</span>  <span class="pl-c"><span class="pl-c">#</span>容器启动完成后首次探测的时间，单位为秒</span>
       <span class="pl-ent">timeoutSeconds</span>: <span class="pl-c1">0</span>   <span class="pl-c"><span class="pl-c">#</span>对容器健康检查探测等待响应的超时时间，单位秒，默认1秒</span>
       <span class="pl-ent">periodSeconds</span>: <span class="pl-c1">0</span>    <span class="pl-c"><span class="pl-c">#</span>对容器监控检查的定期探测时间设置，单位秒，默认10秒一次</span>
       <span class="pl-ent">successThreshold</span>: <span class="pl-c1">0</span>
       <span class="pl-ent">failureThreshold</span>: <span class="pl-c1">0</span>
       <span class="pl-ent">securityContext</span>:
         <span class="pl-s">privileged:false</span>
    <span class="pl-ent">restartPolicy</span>: <span class="pl-s">[Always | Never | OnFailure]#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod</span>
    <span class="pl-ent">nodeSelector</span>: <span class="pl-s">obeject  </span><span class="pl-c"><span class="pl-c">#</span>设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定</span>
    <span class="pl-ent">imagePullSecrets</span>:    <span class="pl-c"><span class="pl-c">#</span>Pull镜像时使用的secret名称，以key：secretkey格式指定</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string</span>
    <span class="pl-s">hostNetwork:false      </span><span class="pl-c"><span class="pl-c">#</span>是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</span>
    <span class="pl-ent">volumes</span>:       <span class="pl-c"><span class="pl-c">#</span>在该pod上定义共享存储卷列表</span>
    - <span class="pl-ent">name</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>共享存储卷名称 （volumes类型有很多种）</span>
      <span class="pl-ent">emptyDir</span>: <span class="pl-s">{}     </span><span class="pl-c"><span class="pl-c">#</span>类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值</span>
      <span class="pl-ent">hostPath</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录</span>
        <span class="pl-ent">path</span>: <span class="pl-s">string     </span><span class="pl-c"><span class="pl-c">#</span>Pod所在宿主机的目录，将被用于同期中mount的目录</span>
      <span class="pl-ent">secret</span>:      <span class="pl-c"><span class="pl-c">#</span>类型为secret的存储卷，挂载集群与定义的secre对象到容器内部</span>
        <span class="pl-ent">scretname</span>: <span class="pl-s">string  </span>
        <span class="pl-ent">items</span>:     
        - <span class="pl-ent">key</span>: <span class="pl-s">string</span>
          <span class="pl-ent">path</span>: <span class="pl-s">string</span>
      <span class="pl-ent">configMap</span>:     <span class="pl-c"><span class="pl-c">#</span>类型为configMap的存储卷，挂载预定义的configMap对象到容器内部</span>
        <span class="pl-ent">name</span>: <span class="pl-s">string</span>
        <span class="pl-ent">items</span>:
        - <span class="pl-ent">key</span>: <span class="pl-s">string</span></pre></div>
<h3>ConfigMap</h3>
<ol>
<li>ConfigMap 可以作为数据卷挂载。ConfigMap 也可被系统的其他组件使用， 而不一定直接暴露给 Pod；</li>
<li>当卷中使用的ConfigMap被更新时，所投射的键最终也会被更新；但是以环境变量方式使用的ConfigMap数据不会被自动更新，更新这些数据需要重新启动Pod；</li>
<li>对于大量使用ConfigMap的集群，可以使用不可变更的ConfigMap；一旦配置文件被标记为不可变更，则无法逆转这一变化，也无法更改data或binaryData字段的内容；</li>
</ol>
<h3>Secret</h3>
<ol>
<li>每个文件最多为1MB，避免用户创建非常大的Secret，进而导致内存耗尽，所以推荐使用资源配额来约束namespace中的个数；</li>
</ol>
<h3>Label</h3>
<div class="highlight highlight-source-shell"><pre class="notranslate">kubectl get nodes --show-labels
<span class="pl-c"><span class="pl-c">#</span> 给节点打标签</span>
kubectl label nodes <span class="pl-k">&lt;</span>your-node-name<span class="pl-k">&gt;</span> ramnum=32</pre></div>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">apiVersion</span>: <span class="pl-c1">v1</span>
<span class="pl-ent">kind</span>: <span class="pl-s">Pod</span>
<span class="pl-ent">metadata</span>:
  <span class="pl-ent">name</span>: <span class="pl-s">nginx</span>
  <span class="pl-ent">labels</span>:
    <span class="pl-ent">env</span>: <span class="pl-s">test</span>
<span class="pl-ent">spec</span>:
  <span class="pl-ent">containers</span>:
  - <span class="pl-ent">name</span>: <span class="pl-s">nginx</span>
    <span class="pl-ent">image</span>: <span class="pl-s">nginx</span>
    <span class="pl-ent">imagePullPolicy</span>: <span class="pl-s">IfNotPresent</span>
  <span class="pl-ent">nodeSelector</span>:
    <span class="pl-ent">ramnum</span>: <span class="pl-c1">32</span>
<span class="pl-c"><span class="pl-c">#</span> 使示例容器调度到指定节点上	</span></pre></div>
<h3>CPU/RAM分配</h3>
<p><strong>CPU</strong></p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">apiVersion</span>: <span class="pl-c1">v1</span>
<span class="pl-ent">kind</span>: <span class="pl-s">Pod</span>
<span class="pl-ent">metadata</span>:
  <span class="pl-ent">name</span>: <span class="pl-s">cpu-demo</span>
  <span class="pl-ent">namespace</span>: <span class="pl-s">cpu-example</span>
<span class="pl-ent">spec</span>:
  <span class="pl-ent">containers</span>:
  - <span class="pl-ent">name</span>: <span class="pl-s">cpu-demo-ctr</span>
    <span class="pl-ent">image</span>: <span class="pl-s">vish/stress</span>
    <span class="pl-ent">resources</span>:
      <span class="pl-ent">limits</span>:
        <span class="pl-ent">cpu</span>: <span class="pl-s"><span class="pl-pds">"</span>1<span class="pl-pds">"</span></span>
      <span class="pl-ent">requests</span>:
        <span class="pl-ent">cpu</span>: <span class="pl-s"><span class="pl-pds">"</span>0.5<span class="pl-pds">"</span></span>
    <span class="pl-ent">args</span>:
    - <span class="pl-s">-cpus</span>
    - <span class="pl-s"><span class="pl-pds">"</span>2<span class="pl-pds">"</span></span>
<span class="pl-c"><span class="pl-c">#</span> 配置文件的 args 部分提供了容器启动时的参数。 -cpus "2" 参数告诉容器尝试使用 2 个 CPU</span>
<span class="pl-c"><span class="pl-c">#</span> 一个容器的 CPU 请求为 500 milliCPU，并且 CPU 限制为 1 个 CPU</span></pre></div>
<p><strong>RAM</strong></p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">apiVersion</span>: <span class="pl-c1">v1</span>
<span class="pl-ent">kind</span>: <span class="pl-s">Pod</span>
<span class="pl-ent">metadata</span>:
  <span class="pl-ent">name</span>: <span class="pl-s">memory-demo</span>
  <span class="pl-ent">namespace</span>: <span class="pl-s">mem-example</span>
<span class="pl-ent">spec</span>:
  <span class="pl-ent">containers</span>:
  - <span class="pl-ent">name</span>: <span class="pl-s">memory-demo-ctr</span>
    <span class="pl-ent">image</span>: <span class="pl-s">polinux/stress</span>
    <span class="pl-ent">resources</span>:
      <span class="pl-ent">requests</span>:
        <span class="pl-ent">memory</span>: <span class="pl-s"><span class="pl-pds">"</span>100Mi<span class="pl-pds">"</span></span>
      <span class="pl-ent">limits</span>:
        <span class="pl-ent">memory</span>: <span class="pl-s"><span class="pl-pds">"</span>200Mi<span class="pl-pds">"</span></span>
    <span class="pl-ent">command</span>: <span class="pl-s">["stress"]</span>
    <span class="pl-ent">args</span>: <span class="pl-s">["--vm", "1", "--vm-bytes", "150M", "--vm-hang", "1"]</span>
<span class="pl-c"><span class="pl-c">#</span> 请求100MiB内存 并且内存会被限制在200MiB内</span>
<span class="pl-c"><span class="pl-c">#</span> 超过容器限制内存：内存溢出被杀掉</span>
<span class="pl-s">NAME            READY     STATUS      RESTARTS   AGE</span>
<span class="pl-s">memory-demo-2   0/1       OOMKilled   1          24s</span>
<span class="pl-c"><span class="pl-c">#</span> 超过整个节点的内存：不会被调度到任何节点上运行，无限期保持此状态</span>
<span class="pl-s">kubectl get pod memory-demo-3 --namespace=mem-example</span>
<span class="pl-s">NAME            READY     STATUS    RESTARTS   AGE</span>
<span class="pl-s">memory-demo-3   0/1       Pending   0          25s</span>
<span class="pl-ent">No nodes are available that match all of the following predicates:</span>: <span class="pl-s">Insufficient memory </span></pre></div>
<h2>Containerd</h2>
<h3>配置私有镜像仓库</h3>
<p><a href="https://github.com/containerd/cri/blob/master/docs/registry.md">https://github.com/containerd/cri/blob/master/docs/registry.md</a></p>
<div class="highlight highlight-source-shell"><pre class="notranslate">vim /etc/containerd/config.toml

[plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>.registry.configs]
        <span class="pl-c"><span class="pl-c">#</span>内部私有仓库认证信息</span>
        [plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>.registry.configs.<span class="pl-s"><span class="pl-pds">"</span>registry.xxx.com<span class="pl-pds">"</span></span>] <span class="pl-c"><span class="pl-c">#</span> 这行不确定要不要写上</span>
        [plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>.registry.configs.<span class="pl-s"><span class="pl-pds">"</span>registry.xxx.com<span class="pl-pds">"</span></span>.tls]
          insecure_skip_verify = <span class="pl-c1">false</span> <span class="pl-c"><span class="pl-c">#</span> 是否跳过证书认证</span>
          ca_file = <span class="pl-s"><span class="pl-pds">"</span>/etc/containerd/registry.xxx.com/1_registry.xxx.com_bundle.crt<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> CA 证书</span>
          cert_file = <span class="pl-s"><span class="pl-pds">"</span>/etc/containerd/registry.xxx.com/1_registry.xxx.com_bundle.crt<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> harbor 证书</span>
          key_file = <span class="pl-s"><span class="pl-pds">"</span>/etc/containerd/registry.xxx.com/2_registry.xxx.com.key<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> harbor 私钥 </span>
        [plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>.registry.configs.<span class="pl-s"><span class="pl-pds">"</span>registry.xxx.com<span class="pl-pds">"</span></span>.auth]
          username = <span class="pl-s"><span class="pl-pds">"</span>jenkins<span class="pl-pds">"</span></span> <span class="pl-c"><span class="pl-c">#</span> 在harbor里单独创建的用户，授权访问指定项目</span>
          password = <span class="pl-s"><span class="pl-pds">"</span>new2020!Ceasia#<span class="pl-pds">"</span></span></pre></div>
<h3>配置镜像仓库secrets</h3>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/pull-image-private-registry/" rel="nofollow">https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/pull-image-private-registry/</a></p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 创建（namespace必须在创建时准确指定）</span>
kubectl create secret docker-registry SECRETNAME \
    --docker-server= \
    --docker-username= \
    --docker-password= \
    --docker-email= \
    -n NAMESPACE
    
<span class="pl-c"><span class="pl-c">#</span> 使用</span>
apiVersion: v1
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
  - name: private-reg-container
    image: your-private-image
  imagePullSecrets:
  - name: SECRETNAME</pre></div>
<h2>指令</h2>
<ol>
<li>检查证书何时过期：<code class="notranslate">kubeadm certs check-expiration</code></li>
<li>检查kubectl已知的位置和凭证：<code class="notranslate">kubectl config view</code></li>
<li>检测命令或者yaml文件是否正确参数：<code class="notranslate">--dry-run=client</code>，不生效deployment同时导出yaml文件：<code class="notranslate">--dry-run=client -o yaml</code></li>
<li>更新Deployment：<code class="notranslate">kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1</code>或<code class="notranslate">kubectl edit deployment/nginx-deployment</code></li>
<li>Deployment修订历史：<code class="notranslate">kubectl roolout history xxx</code></li>
</ol>
<h2>踩坑</h2>
<p><strong>执行<code class="notranslate">crictl images</code>报错： desc = "transport: Error while dialing dial unix /var/run/dockershim.sock: connect: no such file or directory"</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 因为使用的是containerd.service 需要指定k8s的container runtime</span>
crictl config runtime-endpoint unix:///var/run/containerd/containerd.sock</pre></div>
<p><strong>failed to get sandbox image "registry.k8s.io/pause:3.6"</strong></p>
<p>kubeadm init设置的镜像地址不会传递给cri运行时去下载pause镜像，修改/etc/containerd/config.toml文件中sandbox的镜像地址为<code class="notranslate">sandbox_image = "registry.aliyuncs.com/google_containers/pause:3.6"</code>或者打tag</p>
<div class="highlight highlight-source-shell"><pre class="notranslate">crictl pull registry.aliyuncs.com/google_containers/pause:3.6
ctr -n k8s.io i tag registry.aliyuncs.com/google_containers/pause:3.6 registry.k8s.io/pause:3.6</pre></div>
<p><strong>运行kubeadm报错：container runtime is not running: output: time="2023-04-14T14:43:13+08:00" level=fatal msg="validate service connection: CRI v1 runtime API is not implemented for endpoint "unix:///var/run/containerd/containerd.sock": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService"</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span>修改配置</span>
vim /etc/containerd/config.toml

<span class="pl-c"><span class="pl-c">#</span>   Copyright 2018-2022 Docker Inc.</span>

<span class="pl-c"><span class="pl-c">#</span>   Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="pl-c"><span class="pl-c">#</span>   you may not use this file except in compliance with the License.</span>
<span class="pl-c"><span class="pl-c">#</span>   You may obtain a copy of the License at</span>

<span class="pl-c"><span class="pl-c">#</span>       http://www.apache.org/licenses/LICENSE-2.0</span>

<span class="pl-c"><span class="pl-c">#</span>   Unless required by applicable law or agreed to in writing, software</span>
<span class="pl-c"><span class="pl-c">#</span>   distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="pl-c"><span class="pl-c">#</span>   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="pl-c"><span class="pl-c">#</span>   See the License for the specific language governing permissions and</span>
<span class="pl-c"><span class="pl-c">#</span>   limitations under the License.</span>

<span class="pl-c"><span class="pl-c">#</span>disabled_plugins = ["cri"]</span>

<span class="pl-c"><span class="pl-c">#</span>root = "/var/lib/containerd"</span>
<span class="pl-c"><span class="pl-c">#</span>state = "/run/containerd"</span>
<span class="pl-c"><span class="pl-c">#</span>subreaper = true</span>
<span class="pl-c"><span class="pl-c">#</span>oom_score = 0</span>

<span class="pl-c"><span class="pl-c">#</span>[grpc]</span>
<span class="pl-c"><span class="pl-c">#</span>  address = "/run/containerd/containerd.sock"</span>
<span class="pl-c"><span class="pl-c">#</span>  uid = 0</span>
<span class="pl-c"><span class="pl-c">#</span>  gid = 0</span>

<span class="pl-c"><span class="pl-c">#</span>[debug]</span>
<span class="pl-c"><span class="pl-c">#</span>  address = "/run/containerd/debug.sock"</span>
<span class="pl-c"><span class="pl-c">#</span>  uid = 0</span>
<span class="pl-c"><span class="pl-c">#</span>  gid = 0</span>
<span class="pl-c"><span class="pl-c">#</span>  level = "info"</span>

[plugins.<span class="pl-s"><span class="pl-pds">"</span>io.containerd.grpc.v1.cri<span class="pl-pds">"</span></span>]
  sandbox_image = <span class="pl-s"><span class="pl-pds">"</span>registry.aliyuncs.com/google_containers/pause:3.6<span class="pl-pds">"</span></span></pre></div>
<p><strong>crictl报错</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate">WARN[0000] image connect using default endpoints: [unix:///var/run/dockershim.sock unix:///run/containerd/containerd.sock unix:///run/crio/crio.sock unix:///var/run/cri-dockerd.sock]. As the default settings are now deprecated, you should <span class="pl-c1">set</span> the endpoint instead. 
E1124 15:59:57.619574 2290376 remote_image.go:171] <span class="pl-s"><span class="pl-pds">"</span>PullImage from image service failed<span class="pl-pds">"</span></span> err=<span class="pl-s"><span class="pl-pds">"</span>rpc error: code = Unavailable desc = connection error: desc = <span class="pl-cce">\"</span>transport: Error while dialing dial unix /var/run/dockershim.sock: connect: no such file or directory<span class="pl-cce">\"</span><span class="pl-pds">"</span></span> image=<span class="pl-s"><span class="pl-pds">"</span>registry.xxx.com/ceasia_test/sk-biz-eureka:20231124152125<span class="pl-pds">"</span></span>
FATA[0000] pulling image: rpc error: code = Unavailable desc = connection error: desc = <span class="pl-s"><span class="pl-pds">"</span>transport: Error while dialing dial unix /var/run/dockershim.sock: connect: no such file or directory<span class="pl-pds">"</span></span> 

crictl config runtime-endpoint unix:///var/run/containerd/containerd.sock</pre></div>
<p><strong>kubeadm初始化后kube-apiserver无限重启</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate"><span class="pl-c"><span class="pl-c">#</span> 备份/etc/containerd/config.toml</span>
containerd config default
<span class="pl-c"><span class="pl-c">#</span> 将上述指令输出的配置覆盖到config.toml中</span></pre></div>
<p><strong>为什么pod默认不被调度到master上</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate">kubectl describe node dev-33

Taints:             node-role.kubernetes.io/control-plane:NoSchedule
<span class="pl-c"><span class="pl-c">#</span> 默认配置了污点</span></pre></div>
<p><strong>ruby就绪探针</strong></p>
<p>要在Rails框架中对使用Ruby后端服务的Kubernetes就绪探针进行配置，请按以下步骤操作：</p>
<ol>
<li>在Gemfile文件中添加 k8s.io gem：</li>
</ol>
<p><code class="notranslate">gem 'kubernetes-deploy'，'~&gt;1.1.0.beta2'</code></p>
<ol start="2">
<li>运行以下命令启用Rails应用程序中的kubernetes-deploy gem：</li>
</ol>
<p><code class="notranslate">bundle install</code></p>
<ol start="3">
<li>更新您的Kubernetes部署YAML文件以包括就绪探针配置：</li>
</ol>
<pre class="notranslate"><code class="notranslate">apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: app-name
  template:
    metadata:
      labels:
        app: app-name
    spec:
      containers:
        - name: app-container
          image: app-image
          ports:
            - containerPort: 3000
          readinessProbe:
            httpGet:
              path: /health
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 3
</code></pre>
<ol start="4">
<li>在Rails应用程序中定义一个 <code class="notranslate">/health</code>端点，就绪探针可以使用它来检查后端服务是否准备就绪。在Rails中，您可以在 <code class="notranslate">routes.rb</code> 文件中定义此端点，示例如下：</li>
</ol>
<p><code class="notranslate">get '/health', to: 'health#check'</code></p>
<p>在<code class="notranslate">health_controller.rb</code>文件中，定义一个返回成功状态的操作，如果后端服务准备就绪，则为：</p>
<pre class="notranslate"><code class="notranslate">class HealthController &lt; ApplicationController
  def check
    status = :ok
    render json: { status: status }, status: status
  end
end
</code></pre>
<ol start="5">
<li>将更改部署到Kubernetes，并使用 <code class="notranslate">kubectl</code> 监视就绪探针状态：</li>
</ol>
<p><code class="notranslate">kubectl get pods</code></p>
<p>就绪探针状态可以在 <code class="notranslate">READY</code> 列中看到。一旦后端服务准备就绪，状态值将从 <code class="notranslate">0/2</code> 更改为 <code class="notranslate">2/2</code>。</p>
<p>注意：YAML文件中的 <code class="notranslate">initialDelaySeconds</code>、<code class="notranslate">periodSeconds</code>、<code class="notranslate">timeoutSeconds</code>、<code class="notranslate">successThreshold</code> 和 <code class="notranslate">failureThreshold</code> 参数可以根据应用程序的需要进行调整。</p>
<p><strong>初始化ingress-nginx报错cni0" already has an IP address different from 10.2.1.1/24</strong></p>
<div class="highlight highlight-source-shell"><pre class="notranslate">sudo ifconfig cni0 down    
sudo ip link delete cni0</pre></div>
<h2>概念</h2>
<h3>核心组件</h3>
<ol>
<li>CoreDNS（Core Domain Name System）：
<ul>
<li>CoreDNS是Kubernetes中的一个插件式DNS服务器，用于服务发现和名称解析。</li>
<li>它管理集群内部的DNS记录，以便将服务名称解析为相应的IP地址。</li>
</ul>
</li>
<li>etcd：
<ul>
<li>etcd是Kubernetes的分布式键值存储系统，用于存储集群的状态信息。</li>
<li>它存储了有关节点、Pod、服务和其他资源的信息，以及它们的配置和状态。</li>
<li>etcd确保集群中所有组件之间的一致性和可靠性，并提供了高可用性的数据存储。</li>
</ul>
</li>
<li>API Server（API服务器）：
<ul>
<li>API Server是Kubernetes的核心组件之一，作为集群的控制面和所有组件之间的通信接口。</li>
<li>它提供了用于管理和操作集群资源（如Pod、服务、节点等）的RESTful API接口。</li>
<li>API Server负责验证和处理来自用户或其他组件的API请求，并将其转发到适当的组件进行处理。</li>
</ul>
</li>
<li>Controller Manager（控制器管理器）：
<ul>
<li>Controller Manager是一组控制器的集合，负责监控集群的状态并根据预定义的规则自动管理集群。</li>
<li>它包含多个控制器，例如Replication Controller、Deployment Controller和Namespace Controller等。</li>
<li>控制器管理器确保集群中的实际状态与期望状态一致，并根据需要采取适当的操作。</li>
</ul>
</li>
<li>Proxy（代理）：
<ul>
<li>Proxy是Kubernetes的网络代理组件，负责为Pod提供网络代理和负载均衡功能。</li>
<li>它维护集群内部流量的路由规则，并将请求转发到适当的Pod。</li>
<li>Proxy使用IPVS或iptables等技术实现负载均衡，以确保请求能够正确地路由到运行的Pod。</li>
</ul>
</li>
<li>Scheduler（调度器）：
<ul>
<li>Scheduler是Kubernetes的调度器组件，负责将新创建的Pod分配给集群中的节点。</li>
<li>它根据各种策略（如资源需求、节点亲和性等）评估可用节点，并选择最适合的节点来运行Pod。</li>
<li>Scheduler帮助实现Pod的均衡分布和高效利用集群资源。</li>
</ul>
</li>
<li>CNI（Container Network Interface）：
<ul>
<li>CNI是Kubernetes的网络插件规范，用于管理和配置容器网络。</li>
<li>CNI插件负责为Pod创建和管理网络接口，并处理网络规则和路由等配置。</li>
<li>CNI插件可以与不同的网络实现（如flannel、Calico等）集成，以提供容器之间和容器与外部网络之间的通信</li>
</ul>
</li>
</ol>
<h3>namespace</h3>
<blockquote>
<p>对于生产集群，请考虑<strong>不要</strong>使用 <code class="notranslate">default</code> 名字空间，而是创建其他名字空间来使用。</p>
</blockquote>
<p>名字空间适用于存在很多跨多个团队或项目的用户的场景。对于只有几到几十个用户的集群，根本不需要创建或考虑名字空间。当需要名字空间提供的功能时，请开始使用它们。</p>
<p>名字空间为名称提供了一个范围。资源的名称需要在名字空间内是唯一的，但不能跨名字空间。 名字空间不能相互嵌套，每个 Kubernetes 资源只能在一个名字空间中。</p>
<p>不必使用多个名字空间来分隔仅仅轻微不同的资源，例如同一软件的不同版本： 应该使用标签来区分同一名字空间中的不同资源。</p>
<h3>Deployments</h3>
<ul>
<li>Deployment是Kubernetes中的一个高级控制器，用于管理应用程序的部署和更新；</li>
<li>它提供了声明性的方式来定义和管理Pod的副本集，并支持滚动更新和回滚操作；</li>
<li>Deployment确保指定的Pod副本数量运行在集群中，并处理故障恢复和扩缩容等任务；</li>
</ul>
<blockquote>
<p>一些指令</p>
</blockquote>
<ol>
<li>查看Deployment上线状态：<code class="notranslate">kubectl rollout status xxx</code></li>
<li>更新Deployment：<code class="notranslate">kubectl set image deployment/xxx </code>或者<code class="notranslate">kubectl edit deployment/xxx</code>
<ul>
<li>指令后面加上<code class="notranslate">--record</code> 会将当前命令记录到revision记录中，这样我们就可以知道每个revision对应的是哪个配置文件</li>
</ul>
</li>
<li>查看上线状态：<code class="notranslate">kubectl rollout status deployment/xxx</code></li>
<li>查看更新操作：<code class="notranslate">kubectl get rs</code></li>
<li>检查Deployment修订历史：<code class="notranslate">kubectl rollout history deployment xxx</code></li>
<li>查看修订历史的详细信息：<code class="notranslate">kubectl rollout history deployment xxx --revision 2</code></li>
<li>回滚之前的修订版本：<code class="notranslate">kubectl rollout ubdo deployment xxx</code>
<ul>
<li>默认情况下，如果不加<code class="notranslate">--to-revision=版本号</code>，默认回退到上一个版本；</li>
</ul>
</li>
<li>缩放Deployment：<code class="notranslate">kubectl scale deployment xxx --replicas=10</code>或水平自动缩放<code class="notranslate">kubectl autoscale deployment xxx --min=10 --max=15 --cpu-percent=80</code></li>
<li>比例缩放：使用比例缩放时，可以将额外的副本分布到所有ReplicaSet，较大比例的副本会被添加到拥有最多副本的ReplicaSets，而较低比例的副本会进入到副本较少的ReplicaSet；所有剩下的副本都会添加到副本最多的ReplicaSet，具有零副本的ReplicaSet不会被扩容；</li>
<li>暂停上线：<code class="notranslate">kubectl rollout pause deployment xxx</code></li>
<li></li>
</ol>
<p>注：Deployment确保在更新时仅关闭一定数量的Pod，默认情况下，它至少确保所需的Pod的75%处于运行状态（最大不可用比例为25%），当 Deployment 设置为 4 个副本时，Pod 的个数会介于 3 和 5 之间。</p>
<h3>HorizontalPodAutoscaler</h3>
<p><strong>滚动升级时扩缩：</strong></p>
<p>允许在Deployment上执行滚动更新，Deployment管理下层的ReplicaSet，配置自动扩缩时，要为每个Deployment绑定一个HorizontalPodAutoscaler，以此来管理ReplicaSet字段</p>
<p><strong>扩缩策略</strong></p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">behavior</span>:
  <span class="pl-ent">scaleDown</span>:
    <span class="pl-ent">policies</span>:
    - <span class="pl-ent">type</span>: <span class="pl-s">Pods</span>
      <span class="pl-ent">value</span>: <span class="pl-c1">4</span>
      <span class="pl-ent">periodSeconds</span>: <span class="pl-c1">60</span>
    - <span class="pl-ent">type</span>: <span class="pl-s">Percent</span>
      <span class="pl-ent">value</span>: <span class="pl-c1">10</span>
      <span class="pl-ent">periodSeconds</span>: <span class="pl-c1">60</span></pre></div>
<p><code class="notranslate">periodSeconds</code> 表示在过去的多长时间内要求策略值为真。 你可以设置 <code class="notranslate">periodSeconds</code> 的最大值为 1800（半小时）。 第一个策略（Pods）允许在一分钟内最多缩容 4 个副本。第二个策略（Percent） 允许在一分钟内最多缩容当前副本个数的百分之十；</p>
<p>由于默认情况下会选择容许更大程度作出变更的策略，只有 Pod 副本数大于 40 时， 第二个策略才会被采用。如果副本数为 40 或者更少，则应用第一个策略。 例如，如果有 80 个副本，并且目标必须缩小到 10 个副本，那么在第一步中将减少 8 个副本。 在下一轮迭代中，当副本的数量为 72 时，10% 的 Pod 数为 7.2，但是这个数字向上取整为 8。 在 autoscaler 控制器的每个循环中，将根据当前副本的数量重新计算要更改的 Pod 数量。 当副本数量低于 40 时，应用第一个策略（Pods），一次减少 4 个副本；</p>
<blockquote>
<p>可以限制缩容速率，禁用缩容</p>
</blockquote>
<p><strong>基于多向度量指标和自定义度量指标自动扩缩</strong></p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">apiVersion</span>: <span class="pl-s">autoscaling/v2</span>
<span class="pl-ent">kind</span>: <span class="pl-s">HorizontalPodAutoscaler</span>
<span class="pl-ent">metadata</span>:
  <span class="pl-ent">name</span>: <span class="pl-s">php-apache</span>
<span class="pl-ent">spec</span>:
  <span class="pl-ent">scaleTargetRef</span>:
    <span class="pl-ent">apiVersion</span>: <span class="pl-s">apps/v1</span>
    <span class="pl-ent">kind</span>: <span class="pl-s">Deployment</span>
    <span class="pl-ent">name</span>: <span class="pl-s">php-apache</span>
  <span class="pl-ent">minReplicas</span>: <span class="pl-c1">1</span>
  <span class="pl-ent">maxReplicas</span>: <span class="pl-c1">10</span>
  <span class="pl-ent">metrics</span>:
  - <span class="pl-ent">type</span>: <span class="pl-s">Resource</span>
    <span class="pl-ent">resource</span>:
      <span class="pl-ent">name</span>: <span class="pl-s">cpu</span>
      <span class="pl-ent">target</span>:
        <span class="pl-ent">type</span>: <span class="pl-s">Utilization</span>
        <span class="pl-ent">averageUtilization</span>: <span class="pl-c1">50</span>
<span class="pl-ent">status</span>:
  <span class="pl-ent">observedGeneration</span>: <span class="pl-c1">1</span>
  <span class="pl-ent">lastScaleTime</span>: <span class="pl-s">&lt;some-time&gt;</span>
  <span class="pl-ent">currentReplicas</span>: <span class="pl-c1">1</span>
  <span class="pl-ent">desiredReplicas</span>: <span class="pl-c1">1</span>
  <span class="pl-ent">currentMetrics</span>:
  - <span class="pl-ent">type</span>: <span class="pl-s">Resource</span>
    <span class="pl-ent">resource</span>:
      <span class="pl-ent">name</span>: <span class="pl-s">cpu</span>
      <span class="pl-ent">current</span>:
        <span class="pl-ent">averageUtilization</span>: <span class="pl-c1">0</span>
        <span class="pl-ent">averageValue</span>: <span class="pl-c1">0</span></pre></div>
<p>除了cpu外，还可以指定其他资源度量指标；默认情况下目前唯一支持的其他资源度量指标为内存，只要<code class="notranslate">metrics.k8s.io</code>存在，这些资源度量指标就是可用的，并且不会在不同的k8s集群中改变名称；</p>
<p>除了百分比，还可以使用绝对数值来指定资源度量指标，需要将 <code class="notranslate">target.type</code> 从 <code class="notranslate">Utilization</code> 替换成 <code class="notranslate">AverageValue</code>，同时设置 <code class="notranslate">target.averageValue</code> 而非 <code class="notranslate">target.averageUtilization</code> 的值；</p>
<p>还有两种其他类型的度量指标（自定义度量指标）：Pod度量指标和Object度量指标，这些指标可能具有特定于集群的名称，并且需要更高级的集群监控设置；</p>
<p>Pod 度量指标：这些指标从某一方面描述了 Pod， 在不同 Pod 之间进行平均，并通过与一个目标值比对来确定副本的数量。 它们的工作方式与资源度量指标非常相像，只是它们仅支持 target 类型为 AverageValue：</p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">type</span>: <span class="pl-s">Pods</span>
<span class="pl-ent">pods</span>:
  <span class="pl-ent">metric</span>:
    <span class="pl-ent">name</span>: <span class="pl-s">packets-per-second</span>
  <span class="pl-ent">target</span>:
    <span class="pl-ent">type</span>: <span class="pl-s">AverageValue</span>
    <span class="pl-ent">averageValue</span>: <span class="pl-c1">1k</span></pre></div>
<p>Object度量指标：用于描述在相同名字空间中的别的对象，而非 Pod，它们仅用于描述这些对象。 对象度量指标支持的 <code class="notranslate">target</code> 类型包括 <code class="notranslate">Value</code> 和 <code class="notranslate">AverageValue</code>。 如果是 <code class="notranslate">Value</code> 类型，<code class="notranslate">target</code> 值将直接与 API 返回的度量指标比较， 而对于 <code class="notranslate">AverageValue</code> 类型，API 返回的度量值将按照 Pod 数量拆分， 然后再与 <code class="notranslate">target</code> 值比较。 下面的 YAML 文件展示了一个表示 <code class="notranslate">requests-per-second</code> 的度量指标：</p>
<div class="highlight highlight-source-yaml"><pre class="notranslate"><span class="pl-ent">type</span>: <span class="pl-s">Object</span>
<span class="pl-ent">object</span>:
  <span class="pl-ent">metric</span>:
    <span class="pl-ent">name</span>: <span class="pl-s">requests-per-second</span>
  <span class="pl-ent">describedObject</span>:
    <span class="pl-ent">apiVersion</span>: <span class="pl-s">networking.k8s.io/v1</span>
    <span class="pl-ent">kind</span>: <span class="pl-s">Ingress</span>
    <span class="pl-ent">name</span>: <span class="pl-s">main-route</span>
  <span class="pl-ent">target</span>:
    <span class="pl-ent">type</span>: <span class="pl-s">Value</span>
    <span class="pl-ent">value</span>: <span class="pl-c1">2k</span></pre></div>
<h2>YAML文件字段解释</h2>
<ol>
<li>Init Contianer类型的容器，都会比<code class="notranslate">spec.containers</code>定义的容器先启动；并且Init Container类型的容器会按顺序逐一启动；</li>
</ol></div>
<div style="font-size:small;margin-top:8px;float:right;">🍺转载文章请注明出处，谢谢！🍺</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://blog.witter.top">V's Blog</a></div>
<div id="footer2"><span id="filingNum"><a href="https://beian.miit.gov.cn/" target="_blank">冀ICP备2022019998号</a> • </span>
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("06/20/2024"!=""){
    var startSite=new Date("06/20/2024");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","ljwtorch/ljwtorch.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>
<script defer src="http://ssh.witter.top:10012/script.js" data-website-id="b891c729-62b4-46cb-bdca-d622dc706106"></script>

</html>
